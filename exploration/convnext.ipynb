{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, file_prefix = \"\", transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.file_prefix = file_prefix\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(self.data.iloc[:, 2].unique())\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.file_prefix + self.data.iloc[idx, 1] + '.jpg')\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data.iloc[idx, 2]\n",
    "        label_idx = self.class_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label_idx, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = HAM10000Dataset(csv_file='data/archive/HAM10000_metadata.csv', img_dir='data/hair_removed/', file_prefix=\"nohair_\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "\n",
    "def create_model(num_classes=7):\n",
    "    # todo: what weights to use?\n",
    "    model = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # todo: modify the classifier?\n",
    "    model.classifier[2] = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "model = create_model(num_classes=num_classes)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.7056400172738915\n",
      "Validation Loss: 0.5218399500563031, Accuracy: 81.47778332501248%\n",
      "Epoch 2/10, Training Loss: 0.4241863518240917\n",
      "Validation Loss: 0.5172214529344014, Accuracy: 79.73040439340988%\n",
      "Epoch 3/10, Training Loss: 0.239330586654494\n",
      "Validation Loss: 0.44144364682927967, Accuracy: 85.57164253619571%\n",
      "Epoch 4/10, Training Loss: 0.11539133306429443\n",
      "Validation Loss: 0.5863603198575595, Accuracy: 84.47329006490264%\n",
      "Epoch 5/10, Training Loss: 0.074382930044159\n",
      "Validation Loss: 0.6233507359311694, Accuracy: 83.82426360459311%\n",
      "Epoch 6/10, Training Loss: 0.040729698802036536\n",
      "Validation Loss: 0.5935453451755974, Accuracy: 85.87119321018473%\n",
      "Epoch 7/10, Training Loss: 0.038065784589009014\n",
      "Validation Loss: 0.6753175209261595, Accuracy: 85.12231652521218%\n",
      "Epoch 8/10, Training Loss: 0.04428494533484958\n",
      "Validation Loss: 0.6633431913833769, Accuracy: 85.12231652521218%\n",
      "Epoch 9/10, Training Loss: 0.0313248459024615\n",
      "Validation Loss: 0.6457099918098677, Accuracy: 84.97254118821768%\n",
      "Epoch 10/10, Training Loss: 0.04201694484173962\n",
      "Validation Loss: 0.6312782174301526, Accuracy: 85.97104343484773%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        if isinstance(labels, tuple):\n",
    "            labels = labels[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_dataloader)}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            if isinstance(labels, tuple):\n",
    "                labels = labels[0]\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss/len(test_dataloader)}, Accuracy: {100.*correct/total}%\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'akiec', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv']\n",
      "Predicted: ['df', 'nv', 'nv', 'akiec', 'nv', 'mel', 'nv', 'vasc', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'bcc', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'mel']\n",
      "Actual: ['bcc', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'vasc', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'mel', 'bcc', 'nv', 'vasc', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'mel']\n",
      "Predicted: ['nv', 'nv', 'nv', 'df', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'akiec', 'mel', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl']\n",
      "Actual: ['mel', 'mel', 'mel', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'bkl', 'mel', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'bcc', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv']\n",
      "Actual: ['bcc', 'bcc', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv']\n",
      "Predicted: ['vasc', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'akiec', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'mel']\n",
      "Actual: ['vasc', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'akiec', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'bcc', 'nv', 'nv', 'mel']\n",
      "Predicted: ['mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl']\n",
      "Actual: ['mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv', 'bkl', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'bkl']\n",
      "Predicted: ['df', 'bkl', 'nv', 'nv', 'df', 'nv', 'mel', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['df', 'bkl', 'bkl', 'nv', 'bkl', 'nv', 'mel', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'mel']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'akiec', 'bkl']\n",
      "Actual: ['nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'akiec', 'bkl']\n",
      "Predicted: ['mel', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv']\n",
      "Actual: ['akiec', 'nv', 'bcc', 'nv', 'mel', 'mel', 'nv', 'mel', 'nv', 'mel', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv']\n",
      "Predicted: ['mel', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv']\n",
      "Actual: ['nv', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv']\n",
      "Predicted: ['bcc', 'mel', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'bcc', 'bcc', 'df', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['bcc', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'bcc', 'bcc', 'akiec', 'nv', 'df', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'bkl', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'df', 'akiec', 'bkl', 'akiec', 'nv', 'bkl']\n",
      "Actual: ['bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'mel', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'df', 'akiec', 'bkl', 'akiec', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'mel', 'mel', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'bkl', 'mel', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'vasc', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'vasc', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'df', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'df', 'mel', 'bkl', 'nv']\n",
      "Actual: ['nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'df', 'mel', 'bkl', 'nv']\n",
      "Predicted: ['nv', 'akiec', 'nv', 'mel', 'nv', 'nv', 'df', 'vasc', 'vasc', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv']\n",
      "Actual: ['nv', 'akiec', 'nv', 'mel', 'nv', 'nv', 'df', 'vasc', 'vasc', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'akiec', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'mel', 'nv', 'bkl', 'mel', 'mel', 'nv', 'mel', 'mel', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'akiec', 'bkl', 'mel', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'mel', 'bcc', 'nv', 'mel', 'mel', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'vasc', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'bcc', 'nv', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'vasc', 'nv', 'df', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel']\n",
      "Predicted: ['nv', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'df', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'bkl', 'nv', 'mel']\n",
      "Actual: ['mel', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'df', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'bkl', 'nv', 'mel']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Actual: ['bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'df', 'mel', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'akiec', 'bkl', 'mel', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'bkl', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv']\n",
      "Actual: ['nv', 'bkl', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'akiec', 'bkl', 'nv', 'bkl', 'akiec', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'mel', 'bcc', 'df', 'nv', 'nv', 'bkl', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'akiec', 'akiec', 'nv', 'bkl', 'bcc', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'bkl', 'bcc', 'bcc', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'bkl', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'df', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'bkl', 'nv', 'mel', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'mel', 'nv', 'nv', 'nv', 'df', 'nv']\n",
      "Predicted: ['akiec', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'mel', 'nv']\n",
      "Actual: ['akiec', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'nv', 'bkl', 'nv']\n",
      "Predicted: ['nv', 'bcc', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'df', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'bcc']\n",
      "Actual: ['mel', 'bcc', 'bkl', 'nv', 'akiec', 'nv', 'nv', 'bcc', 'nv', 'df', 'bkl', 'nv', 'mel', 'bkl', 'nv', 'mel', 'nv', 'nv', 'bkl', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'bcc']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'mel', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bcc', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'bcc', 'nv', 'bcc', 'mel', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'bcc', 'mel', 'nv', 'vasc', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['mel', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv']\n",
      "Actual: ['mel', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'akiec', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv']\n",
      "Predicted: ['nv', 'bcc', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Actual: ['nv', 'bcc', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bcc', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'akiec', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'bcc', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'vasc', 'bkl', 'mel', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'akiec', 'mel', 'nv', 'nv', 'nv', 'mel', 'akiec', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Actual: ['mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'vasc', 'akiec', 'bkl', 'mel', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'bkl', 'nv', 'nv', 'mel', 'mel', 'akiec', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'vasc', 'nv', 'nv', 'bkl']\n",
      "Actual: ['nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'vasc', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'bkl']\n",
      "Actual: ['nv', 'mel', 'akiec', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'bkl', 'bcc', 'nv', 'bkl', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'df', 'nv', 'nv', 'akiec', 'bkl']\n",
      "Actual: ['nv', 'nv', 'nv', 'bcc', 'nv', 'bcc', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'mel', 'bkl', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'df', 'bcc', 'nv', 'bcc', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'vasc', 'akiec', 'nv', 'mel', 'nv', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'mel', 'nv', 'vasc', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'bkl', 'mel', 'nv', 'df', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv']\n",
      "Actual: ['nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'mel', 'nv', 'mel', 'bkl', 'mel', 'mel', 'nv', 'bcc', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl', 'nv', 'mel']\n",
      "Predicted: ['mel', 'df', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv']\n",
      "Actual: ['bkl', 'df', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'bcc', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'akiec']\n",
      "Actual: ['nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'akiec', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'df', 'bcc', 'nv', 'nv', 'nv', 'bcc', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'akiec']\n",
      "Predicted: ['nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'akiec', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv']\n",
      "Actual: ['bkl', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'bcc', 'df', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'bcc', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv']\n",
      "Predicted: ['nv', 'bkl', 'bcc', 'bkl', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv']\n",
      "Actual: ['nv', 'bkl', 'bcc', 'nv', 'nv', 'nv', 'vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'akiec', 'mel', 'nv', 'mel', 'mel', 'nv', 'bcc', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'akiec', 'mel', 'mel', 'mel', 'mel', 'nv', 'bcc', 'mel', 'nv']\n",
      "Predicted: ['nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bcc', 'nv', 'bkl', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'bcc', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'mel', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'mel', 'mel', 'bcc', 'nv', 'nv', 'bkl', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'bkl', 'mel', 'bkl', 'bkl', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'akiec', 'nv', 'nv', 'bkl']\n",
      "Actual: ['nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'mel', 'mel', 'bcc', 'bkl', 'nv', 'akiec', 'nv', 'bkl', 'nv', 'nv', 'mel', 'bkl', 'nv', 'akiec', 'nv', 'nv', 'bkl']\n",
      "Predicted: ['nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'bcc', 'nv', 'bcc', 'nv', 'bkl', 'bkl', 'nv', 'bkl', 'mel', 'mel', 'mel', 'nv', 'bkl', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv']\n",
      "Actual: ['bcc', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'akiec', 'bkl', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'mel']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'df', 'nv', 'akiec', 'bkl', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'mel', 'mel', 'nv', 'nv', 'nv', 'mel']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'bcc', 'nv', 'akiec', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'akiec', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl']\n",
      "Predicted: ['vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'mel', 'vasc', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['vasc', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'mel', 'vasc', 'bcc', 'nv', 'mel', 'mel', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'bcc', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'vasc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'df', 'mel']\n",
      "Actual: ['nv', 'nv', 'vasc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'mel', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'akiec', 'nv', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'nv', 'bkl', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'bkl', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'bkl', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bcc', 'nv']\n",
      "Actual: ['nv', 'bkl', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'bkl', 'nv', 'nv', 'bcc', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'df', 'nv', 'df', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'df', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'nv', 'bkl', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['bkl', 'nv', 'bcc', 'nv', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv']\n",
      "Actual: ['bkl', 'nv', 'bcc', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'vasc', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'bkl', 'nv', 'mel', 'nv', 'nv', 'nv']\n",
      "Actual: ['nv', 'bkl', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'vasc', 'mel', 'nv', 'bkl', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'bkl', 'bkl', 'bkl', 'nv', 'df', 'nv', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'df', 'bkl', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'akiec', 'bkl', 'nv', 'nv', 'nv', 'df', 'nv', 'nv']\n",
      "Actual: ['nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'bkl', 'mel', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'df', 'bcc', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'akiec', 'bkl', 'nv', 'nv', 'mel', 'df', 'nv', 'nv']\n",
      "Predicted: ['nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'vasc', 'bcc', 'bkl', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'mel', 'nv', 'nv', 'akiec', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'bcc', 'nv', 'bkl']\n",
      "Actual: ['nv', 'akiec', 'nv', 'nv', 'nv', 'nv', 'vasc', 'bcc', 'bkl', 'nv', 'nv', 'mel', 'bkl', 'nv', 'mel', 'mel', 'nv', 'nv', 'akiec', 'nv', 'mel', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bkl', 'nv', 'bcc', 'nv', 'bkl']\n",
      "Predicted: ['mel', 'akiec', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'df', 'nv', 'vasc', 'nv', 'mel', 'nv', 'nv', 'bcc', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Actual: ['mel', 'akiec', 'akiec', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'bcc', 'nv', 'vasc', 'nv', 'mel', 'nv', 'nv', 'bcc', 'nv', 'nv', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv', 'nv']\n",
      "Predicted: ['akiec', 'akiec', 'bkl', 'bkl', 'nv', 'bkl', 'bkl', 'bcc', 'bcc', 'df', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv']\n",
      "Actual: ['bcc', 'bcc', 'bkl', 'bkl', 'nv', 'akiec', 'bkl', 'bcc', 'bcc', 'df', 'mel', 'nv', 'nv', 'nv', 'nv', 'nv', 'mel', 'nv', 'nv']\n",
      "Accuracy: 85.97104343484773%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Convert numeric predictions back to string labels if needed\n",
    "        predicted_labels = [idx_to_class[idx.item()] for idx in predicted]\n",
    "        true_labels = [idx_to_class[idx.item()] for idx in labels]\n",
    "\n",
    "        print(f\"Predicted: {predicted_labels}\")\n",
    "        print(f\"Actual: {true_labels}\")\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
