{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                        image_path  \n",
      "0  /home/rob/ham10000_data/images/ISIC_0027419.jpg  \n",
      "1  /home/rob/ham10000_data/images/ISIC_0025030.jpg  \n",
      "2  /home/rob/ham10000_data/images/ISIC_0026769.jpg  \n",
      "3  /home/rob/ham10000_data/images/ISIC_0025661.jpg  \n",
      "4  /home/rob/ham10000_data/images/ISIC_0031633.jpg  \n"
     ]
    }
   ],
   "source": [
    "base = '/home/rob/'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "class_names = df['dx'].unique()\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(224, 224, 3), num_classes=7, base_trainable=False, learning_rate=0.001, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Builds and compiles a ResNet50-based model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images (default: (224, 224, 3)).\n",
    "        num_classes (int): Number of output classes (default: 7).\n",
    "        base_trainable (bool): Whether to make the base ResNet50 model trainable (default: False).\n",
    "        learning_rate (float): Learning rate for the optimizer (default: 0.001).\n",
    "        dropout_rate (float): Dropout rate after the GlobalAveragePooling2D layer (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "        Model: A compiled Keras model.\n",
    "    \"\"\"\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = base_trainable\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/best_model_resnet50.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1...\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 46\u001b[0m\n\u001b[1;32m     33\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: train_generator,\n\u001b[1;32m     35\u001b[0m     output_types\u001b[38;5;241m=\u001b[39m(tf\u001b[38;5;241m.\u001b[39mfloat32, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     36\u001b[0m     output_shapes\u001b[38;5;241m=\u001b[39m([\u001b[38;5;28;01mNone\u001b[39;00m, IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlen\u001b[39m(class_names)])\n\u001b[1;32m     37\u001b[0m )\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     39\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: val_generator,\n\u001b[1;32m     41\u001b[0m     output_types\u001b[38;5;241m=\u001b[39m(tf\u001b[38;5;241m.\u001b[39mfloat32, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     42\u001b[0m     output_shapes\u001b[38;5;241m=\u001b[39m([\u001b[38;5;28;01mNone\u001b[39;00m, IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlen\u001b[39m(class_names)])\n\u001b[1;32m     43\u001b[0m )\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_trainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     50\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m ]\n\u001b[1;32m     53\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     54\u001b[0m     train_dataset,\n\u001b[1;32m     55\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[1;32m     60\u001b[0m )\n",
      "Cell \u001b[0;32mIn[34], line 15\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, num_classes, base_trainable, learning_rate, dropout_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, base_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Builds and compiles a ResNet50-based model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m        Model: A compiled Keras model.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m base_trainable\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m GlobalAveragePooling2D()(base_model\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/applications/resnet.py:409\u001b[0m, in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    406\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/applications/resnet.py:163\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mZeroPadding2D(padding\u001b[38;5;241m=\u001b[39m((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool1_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m    161\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(\u001b[38;5;241m3\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool1_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[0;32m--> 163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mstack_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preact:\n\u001b[1;32m    166\u001b[0m     x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization(\n\u001b[1;32m    167\u001b[0m         axis\u001b[38;5;241m=\u001b[39mbn_axis, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.001e-5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_bn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )(x)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/applications/resnet.py:404\u001b[0m, in \u001b[0;36mResNet50.<locals>.stack_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_fn\u001b[39m(x):\n\u001b[0;32m--> 404\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstack_residual_blocks_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m4\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/applications/resnet.py:290\u001b[0m, in \u001b[0;36mstack_residual_blocks_v1\u001b[0;34m(x, filters, blocks, stride1, name)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_residual_blocks_v1\u001b[39m(x, filters, blocks, stride1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A set of stacked residual blocks.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        Output tensor for the stacked blocks.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mresidual_block_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_block1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, blocks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    292\u001b[0m         x \u001b[38;5;241m=\u001b[39m residual_block_v1(\n\u001b[1;32m    293\u001b[0m             x, filters, conv_shortcut\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_block\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[1;32m    294\u001b[0m         )\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/applications/resnet.py:264\u001b[0m, in \u001b[0;36mresidual_block_v1\u001b[0;34m(x, filters, kernel_size, stride, conv_shortcut, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\n\u001b[1;32m    259\u001b[0m     filters, kernel_size, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAME\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_2_conv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m )(x)\n\u001b[1;32m    261\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization(\n\u001b[1;32m    262\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbn_axis, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.001e-5\u001b[39m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_2_bn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m )(x)\n\u001b[0;32m--> 264\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_2_relu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m filters, \u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_3_conv\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m    267\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization(\n\u001b[1;32m    268\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbn_axis, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.001e-5\u001b[39m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_3_bn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m )(x)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/layers/layer.py:816\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    811\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[0;32m--> 816\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m \u001b[43mCallSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# 3. Check input spec for 1st positional arg.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# TODO: consider extending this to all args and kwargs.\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_input_compatibility(call_spec\u001b[38;5;241m.\u001b[39mfirst_arg)\n",
      "File \u001b[0;32m~/.notebook/lib/python3.10/site-packages/keras/src/layers/layer.py:1572\u001b[0m, in \u001b[0;36mCallSpec.__init__\u001b[0;34m(self, signature, args, kwargs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     bound_args \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_arguments_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1570\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m bound_args\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1571\u001b[0m }\n\u001b[0;32m-> 1572\u001b[0m \u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1574\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3.10/inspect.py:2840\u001b[0m, in \u001b[0;36mBoundArguments.apply_defaults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2836\u001b[0m                 kwargs[param_name] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m   2838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n\u001b[0;32m-> 2840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_defaults\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set default values for missing arguments.\u001b[39;00m\n\u001b[1;32m   2842\u001b[0m \n\u001b[1;32m   2843\u001b[0m \u001b[38;5;124;03m    For variable-positional arguments (*args) the default is an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m    empty dict.\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2849\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marguments\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = 'models/best_model_overall_resnet50.keras'\n",
    "\n",
    "fold_results = []\n",
    "for fold_no, (train_idx, val_idx) in enumerate(skf.split(df, df['dx']), 1):\n",
    "    print(f\"Training Fold {fold_no}...\")\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    train_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = datagen_test.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: train_generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: val_generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    model = build_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=num_classes, base_trainable=False)\n",
    "\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=20,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(val_generator, steps=len(val_generator))\n",
    "    print(f\"Fold {fold_no} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.save(best_model_path)\n",
    "        print(f\"New Best Model Saved with Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    fold_results.append({'fold': fold_no, 'val_loss': val_loss, 'val_accuracy': val_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n",
    "std_val_accuracy = np.std([result['val_accuracy'] for result in fold_results])\n",
    "print(f\"Cross-Validation Mean Accuracy: {avg_val_accuracy:.4f} ± {std_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Final Model on Full Dataset...\")\n",
    "final_train_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = 'best_models/resnet50.keras'\n",
    "\n",
    "final_model = build_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=num_classes, base_trainable=True, learning_rate=1e-5)\n",
    "final_model.fit(\n",
    "    final_train_generator,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(final_train_generator),\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=final_model_path, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating Best Model on Test Set...\")\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "loss, accuracy = best_model.evaluate(val_generator, steps=len(val_generator))\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(best_model.predict(val_generator), axis=-1)\n",
    "y_true = val_generator.classes\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "y_pred_prob = best_model.predict(val_generator)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true_one_hot.ravel(), y_pred_prob.ravel())\n",
    "auc_score = roc_auc_score(y_true_one_hot, y_pred_prob, average=\"micro\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f\"Micro-Average ROC Curve (AUC = {auc_score:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
