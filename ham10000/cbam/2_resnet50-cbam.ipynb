{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Layer, Reshape, Multiply, Conv2D, BatchNormalization, Activation, Add, Input, ZeroPadding2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/home/rob/'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in sss.split(df, df['dx']):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "print(\"Train size: \", len(train_df))\n",
    "print(\"Train sizes per label and percentage:\")\n",
    "train_counts = train_df['dx'].value_counts()\n",
    "train_percentages = (train_counts / len(train_df)) * 100\n",
    "print(train_counts)\n",
    "print(train_percentages)\n",
    "\n",
    "print(\"\\nTest size: \", len(test_df))\n",
    "print(\"Test sizes per label and percentage:\")\n",
    "test_counts = test_df['dx'].value_counts()\n",
    "test_percentages = (test_counts / len(test_df)) * 100\n",
    "print(test_counts)\n",
    "print(test_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = datagen_test.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "class_names = [key for key, _ in sorted(train_generator.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    ").repeat()\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: test_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    ").repeat()\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Train Generator Class Indices:\", train_generator.class_indices)\n",
    "print(\"Test Generator Class Indices:\", test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Block Attention Module (CBAM)\n",
    "\n",
    "    Reference: \"CBAM: Convolutional Block Attention Module\"\n",
    "    (Woo et al., ECCV 2018) - https://arxiv.org/abs/1807.06521\n",
    "\n",
    "    The CBAM block applies both Channel Attention and Spatial Attention\n",
    "    to refine feature maps adaptively. It consists of two sequential sub-blocks:\n",
    "\n",
    "    1. Channel Attention Module (CAM):\n",
    "       - Uses both global average and max pooling operations to generate channel descriptors.\n",
    "       - Passes them through a shared MLP to produce channel-wise weights.\n",
    "       - The output is a channel attention map that emphasizes meaningful channels.\n",
    "\n",
    "    2. Spatial Attention Module (SAM):\n",
    "       - Uses average and max pooling along the channel dimension to produce spatial descriptors.\n",
    "       - Applies a convolution (often 7x7) to produce a spatial attention map.\n",
    "       - This map emphasizes \"where\" to focus within each channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reduction_ratio : int, optional (default=16)\n",
    "        Reduction ratio for the internal MLP in the channel attention module.\n",
    "\n",
    "    spatial_kernel_size : int, optional (default=7)\n",
    "        The kernel size for the spatial attention convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, spatial_kernel_size=7, name=None, **kwargs):\n",
    "        super(CBAM, self).__init__(name=name, **kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.spatial_kernel_size = spatial_kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"CBAM input must be in the shape: (batch, height, width, channels)\")\n",
    "\n",
    "        channels = input_shape[-1]\n",
    "        reduced_channels = max(channels // self.reduction_ratio, 1)\n",
    "\n",
    "        # Shared MLP for channel attention\n",
    "        # Two Dense layers: C -> C//r -> C\n",
    "        self.mlp_dense_1 = Dense(units=reduced_channels,\n",
    "                                        activation='relu',\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_1')\n",
    "        self.mlp_dense_2 = Dense(units=channels,\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_2')\n",
    "\n",
    "        # No weights needed to pre-build for the spatial attention layer\n",
    "        # since we'll use a Conv2D layer directly on the fly.\n",
    "        self.spatial_conv = Conv2D(filters=1,\n",
    "                                          kernel_size=self.spatial_kernel_size,\n",
    "                                          strides=1,\n",
    "                                          padding='same',\n",
    "                                          activation='sigmoid',\n",
    "                                          use_bias=False,\n",
    "                                          name='spatial_conv')\n",
    "\n",
    "        super(CBAM, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # ----- Channel Attention -----\n",
    "        # Global average pooling\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)  # (batch, C)\n",
    "        # Global max pooling\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=False)   # (batch, C)\n",
    "\n",
    "        # Shared MLP transforms\n",
    "        avg_out = self.mlp_dense_2(self.mlp_dense_1(avg_pool, training=training), training=training)\n",
    "        max_out = self.mlp_dense_2(self.mlp_dense_1(max_pool, training=training), training=training)\n",
    "\n",
    "        # Combine and apply sigmoid\n",
    "        channel_attention = tf.nn.sigmoid(avg_out + max_out)  # (batch, C)\n",
    "\n",
    "        # Reshape to broadcast\n",
    "        channel_attention = tf.reshape(channel_attention, [-1, 1, 1, tf.shape(inputs)[-1]])\n",
    "        channel_refined = inputs * channel_attention\n",
    "\n",
    "        # ----- Spatial Attention -----\n",
    "        # Avg and max along channel axis\n",
    "        avg_spatial = tf.reduce_mean(channel_refined, axis=-1, keepdims=True)  # (batch, H, W, 1)\n",
    "        max_spatial = tf.reduce_max(channel_refined, axis=-1, keepdims=True)   # (batch, H, W, 1)\n",
    "\n",
    "        # Concatenate along channel axis\n",
    "        spatial_concat = tf.concat([avg_spatial, max_spatial], axis=-1)  # (batch, H, W, 2)\n",
    "\n",
    "        # Apply spatial conv\n",
    "        spatial_attention = self.spatial_conv(spatial_concat, training=training)  # (batch, H, W, 1)\n",
    "\n",
    "        # Refine features spatially\n",
    "        refined_outputs = channel_refined * spatial_attention\n",
    "        return refined_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CBAM, self).get_config()\n",
    "        config.update({\n",
    "            'reduction_ratio': self.reduction_ratio,\n",
    "            'spatial_kernel_size': self.spatial_kernel_size\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/keras-team/keras/blob/v3.7.0/keras/src/applications/resnet.py#L219\n",
    "# This implementation of ResNet50 is adapted from the official Keras implementation,\n",
    "# to enable the modification of the architecture to support attention mechanisms.\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of the middle conv layer at the main path\n",
    "        filters: list of integers, the filters of the 3 conv layers at the main path\n",
    "        stage: integer, current stage label, used for layer naming\n",
    "        block: string/char, current block label, used for layer naming\n",
    "    \"\"\"\n",
    "    # Use channels_last\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'conv' + str(stage) + '_block' + str(block) + '_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, input_tensor])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of the middle conv layer at the main path\n",
    "        filters: list of integers, the filters of the 3 conv layers at the main path\n",
    "        stage: integer, current stage label, used for layer naming\n",
    "        block: string/char, current block label, used for layer naming\n",
    "        strides: Strides for the first conv layer in the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'conv' + str(stage) + '_block' + str(block) + '_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '0_conv')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '0_bn')(shortcut)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, shortcut])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape, name='input_1')\n",
    "    bn_axis = 3  # channels_last\n",
    "\n",
    "    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "               padding='valid', use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name='conv1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1_pool')(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    # Stage 3\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    # Stage 4\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    # Stage 5\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    x = CBAM()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name='resnet50')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(base_model, target_model):\n",
    "    for layer in target_model.layers:\n",
    "        try:\n",
    "            pretrained_layer = base_model.get_layer(layer.name)\n",
    "            layer.set_weights(pretrained_layer.get_weights())\n",
    "        except Exception as e:\n",
    "            print(f\"Could not transfer weights for layer: {layer.name}, due to: {e}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=None)\n",
    "\n",
    "# Build ResNet50 with SE Blocks\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 7\n",
    "custom_resnet = build_resnet50(input_shape, num_classes)\n",
    "\n",
    "# Transfer weights\n",
    "transfer_weights(base_model, custom_resnet)\n",
    "\n",
    "custom_resnet.summary()\n",
    "\n",
    "# Switch the custom_resnet to being the model\n",
    "model = custom_resnet\n",
    "\n",
    "# Freeze the base model\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('conv1') or layer.name.startswith('conv2') or layer.name.startswith('conv3') or layer.name.startswith('conv4') or layer.name.startswith('conv5'):\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    \"\"\"\n",
    "    Focal Loss for one-hot encoded multi-class data.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: Weighting factor for positive classes, default is 0.25.\n",
    "    - gamma: Focusing parameter to reduce the loss contribution from well-classified examples, default is 2.0.\n",
    "\n",
    "    Returns:\n",
    "    - A callable loss function for use with Keras models.\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "\n",
    "        # Compute focal loss components\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weights = alpha * y_true * tf.math.pow(1 - y_pred, gamma)\n",
    "\n",
    "        # Compute weighted loss\n",
    "        focal_loss = tf.reduce_sum(weights * cross_entropy, axis=-1)\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "\n",
    "    return focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/best_model_resnet50_seblock_classification_head.keras'\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(class_names),\n",
    "    y=df['dx']\n",
    ")\n",
    "\n",
    "class_weights_dict = {\n",
    "    train_generator.class_indices[class_name]: weight\n",
    "    for class_name, weight in zip(class_names, class_weights_array)\n",
    "}\n",
    "\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "validation_steps = len(test_df) // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Total Predictions: {len(test_generator) * BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy'] + fine_tune_history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy'] + fine_tune_history.history['val_accuracy']\n",
    "loss = history.history['loss'] + fine_tune_history.history['loss']\n",
    "val_loss = history.history['val_loss'] + fine_tune_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "plt.axvline(x=len(history.history['accuracy']), color='r', linestyle='--', label='Start of Fine-Tuning')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.axvline(x=len(history.history['loss']), color='r', linestyle='--', label='Start of Fine-Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_generator), axis=-1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.bincount(y_true)\n",
    "class_accuracies = np.diag(cm) / label_counts\n",
    "\n",
    "classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "total_counts = label_counts\n",
    "accuracies = class_accuracies\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.bar(classes, total_counts, alpha=0.7, label='Total Samples', color='blue')\n",
    "ax1.set_xlabel('Classes')\n",
    "ax1.set_ylabel('Total Samples', color='blue')\n",
    "ax1.set_title('Per-Class Total Samples and Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(classes, accuracies, color='orange', marker='o', label='Accuracy')\n",
    "ax2.set_ylabel('Accuracy', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall ROC AUC for multi-class classification\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = len(classes)\n",
    "y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "\n",
    "y_pred_prob = np.zeros_like(y_true_one_hot)\n",
    "for i, label in enumerate(y_pred):\n",
    "    y_pred_prob[i, label] = 1\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true_one_hot.ravel(), y_pred_prob.ravel())\n",
    "roc_auc = roc_auc_score(y_true_one_hot, y_pred_prob, average=\"micro\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", label=f\"Micro-Average ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Overall ROC Curve and AUC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
