{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Layer, Reshape, Multiply, Conv2D, BatchNormalization, Activation, Add, Input, ZeroPadding2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                          image_path  \n",
      "0  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "1  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "2  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "3  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "4  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "Total samples in dataset: 10015\n"
     ]
    }
   ],
   "source": [
    "base = '/Users/robp/scm/personal/github.com/robpickerill/thesis'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Total samples in dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable(package=\"Custom\")\n",
    "class CBAM(Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Block Attention Module (CBAM)\n",
    "\n",
    "    Reference: \"CBAM: Convolutional Block Attention Module\"\n",
    "    (Woo et al., ECCV 2018) - https://arxiv.org/abs/1807.06521\n",
    "\n",
    "    The CBAM block applies both Channel Attention and Spatial Attention\n",
    "    to refine feature maps adaptively. It consists of two sequential sub-blocks:\n",
    "\n",
    "    1. Channel Attention Module (CAM):\n",
    "       - Uses both global average and max pooling operations to generate channel descriptors.\n",
    "       - Passes them through a shared MLP to produce channel-wise weights.\n",
    "       - The output is a channel attention map that emphasizes meaningful channels.\n",
    "\n",
    "    2. Spatial Attention Module (SAM):\n",
    "       - Uses average and max pooling along the channel dimension to produce spatial descriptors.\n",
    "       - Applies a convolution (often 7x7) to produce a spatial attention map.\n",
    "       - This map emphasizes \"where\" to focus within each channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reduction_ratio : int, optional (default=16)\n",
    "        Reduction ratio for the internal MLP in the channel attention module.\n",
    "\n",
    "    spatial_kernel_size : int, optional (default=7)\n",
    "        The kernel size for the spatial attention convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, spatial_kernel_size=7, name=None, **kwargs):\n",
    "        super(CBAM, self).__init__(name=name, **kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.spatial_kernel_size = spatial_kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"CBAM input must be in the shape: (batch, height, width, channels)\")\n",
    "\n",
    "        channels = input_shape[-1]\n",
    "        reduced_channels = max(channels // self.reduction_ratio, 1)\n",
    "\n",
    "        # Shared MLP for channel attention\n",
    "        # Two Dense layers: C -> C//r -> C\n",
    "        self.mlp_dense_1 = Dense(units=reduced_channels,\n",
    "                                        activation='relu',\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_1')\n",
    "        self.mlp_dense_2 = Dense(units=channels,\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_2')\n",
    "\n",
    "        # No weights needed to pre-build for the spatial attention layer\n",
    "        # since we'll use a Conv2D layer directly on the fly.\n",
    "        self.spatial_conv = Conv2D(filters=1,\n",
    "                                          kernel_size=self.spatial_kernel_size,\n",
    "                                          strides=1,\n",
    "                                          padding='same',\n",
    "                                          activation='sigmoid',\n",
    "                                          use_bias=False,\n",
    "                                          name='spatial_conv')\n",
    "\n",
    "        super(CBAM, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # ----- Channel Attention -----\n",
    "        # Global average pooling\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)  # (batch, C)\n",
    "        # Global max pooling\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=False)   # (batch, C)\n",
    "\n",
    "        # Shared MLP transforms\n",
    "        avg_out = self.mlp_dense_2(self.mlp_dense_1(avg_pool, training=training), training=training)\n",
    "        max_out = self.mlp_dense_2(self.mlp_dense_1(max_pool, training=training), training=training)\n",
    "\n",
    "        # Combine and apply sigmoid\n",
    "        channel_attention = tf.nn.sigmoid(avg_out + max_out)  # (batch, C)\n",
    "\n",
    "        # Reshape to broadcast\n",
    "        channel_attention = tf.reshape(channel_attention, [-1, 1, 1, tf.shape(inputs)[-1]])\n",
    "        channel_refined = inputs * channel_attention\n",
    "\n",
    "        # ----- Spatial Attention -----\n",
    "        # Avg and max along channel axis\n",
    "        avg_spatial = tf.reduce_mean(channel_refined, axis=-1, keepdims=True)  # (batch, H, W, 1)\n",
    "        max_spatial = tf.reduce_max(channel_refined, axis=-1, keepdims=True)   # (batch, H, W, 1)\n",
    "\n",
    "        # Concatenate along channel axis\n",
    "        spatial_concat = tf.concat([avg_spatial, max_spatial], axis=-1)  # (batch, H, W, 2)\n",
    "\n",
    "        # Apply spatial conv\n",
    "        spatial_attention = self.spatial_conv(spatial_concat, training=training)  # (batch, H, W, 1)\n",
    "\n",
    "        # Refine features spatially\n",
    "        refined_outputs = channel_refined * spatial_attention\n",
    "        return refined_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CBAM, self).get_config()\n",
    "        config.update({\n",
    "            'reduction_ratio': self.reduction_ratio,\n",
    "            'spatial_kernel_size': self.spatial_kernel_size\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, input_tensor])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '0_conv')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '0_bn')(shortcut)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, shortcut])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape, name='input_1')\n",
    "    bn_axis = 3  # channels_last\n",
    "\n",
    "    # Stage 1\n",
    "    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "               padding='valid', use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name='conv1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1_pool')(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    # Stage 3\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    # Stage 4\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    # Stage 5\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    # CBAM\n",
    "    x = CBAM()(x)\n",
    "\n",
    "    # Global Pooling & Classifier\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name='resnet50')\n",
    "    return model\n",
    "\n",
    "def transfer_weights(base_model, target_model):\n",
    "    \"\"\"\n",
    "    Transfer weights from a Keras ResNet50 base_model into the custom ResNet50\n",
    "    architecture whenever layer names match.\n",
    "    \"\"\"\n",
    "    for layer in target_model.layers:\n",
    "        try:\n",
    "            pretrained_layer = base_model.get_layer(layer.name)\n",
    "            layer.set_weights(pretrained_layer.get_weights())\n",
    "        except Exception:\n",
    "            # If layer doesn't exist in pretrained base, skip\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weights = alpha * y_true * tf.math.pow((1 - y_pred), gamma)\n",
    "        return tf.reduce_mean(tf.reduce_sum(weights * cross_entropy, axis=-1))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights dict: {0: 4.375273044997815, 1: 2.78349082823791, 2: 1.301832835044846, 3: 12.440993788819876, 4: 1.2854575792581184, 5: 0.21338020666879728, 6: 10.075452716297788}\n",
      "\n",
      "\n",
      "===== FOLD 1/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6688 - auc: 0.8499 - loss: 0.2176\n",
      "Epoch 1: val_auc improved from -inf to 0.87374, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 288ms/step - accuracy: 0.6688 - auc: 0.8500 - loss: 0.2176 - val_accuracy: 0.6695 - val_auc: 0.8737 - val_loss: 0.1763\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6761 - auc: 0.8763 - loss: 0.1824\n",
      "Epoch 2: val_auc improved from 0.87374 to 0.88188, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 270ms/step - accuracy: 0.6760 - auc: 0.8763 - loss: 0.1824 - val_accuracy: 0.6695 - val_auc: 0.8819 - val_loss: 0.1715\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6655 - auc: 0.8755 - loss: 0.1834\n",
      "Epoch 3: val_auc improved from 0.88188 to 0.88401, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 268ms/step - accuracy: 0.6655 - auc: 0.8755 - loss: 0.1834 - val_accuracy: 0.6695 - val_auc: 0.8840 - val_loss: 0.1716\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6663 - auc: 0.8751 - loss: 0.1873\n",
      "Epoch 4: val_auc improved from 0.88401 to 0.88736, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.6663 - auc: 0.8751 - loss: 0.1872 - val_accuracy: 0.6695 - val_auc: 0.8874 - val_loss: 0.1708\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6706 - auc: 0.8806 - loss: 0.1780\n",
      "Epoch 5: val_auc improved from 0.88736 to 0.88947, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.6706 - auc: 0.8805 - loss: 0.1781 - val_accuracy: 0.6695 - val_auc: 0.8895 - val_loss: 0.1700\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6674 - auc: 0.8750 - loss: 0.1915\n",
      "Epoch 6: val_auc improved from 0.88947 to 0.89074, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6674 - auc: 0.8750 - loss: 0.1915 - val_accuracy: 0.6695 - val_auc: 0.8907 - val_loss: 0.1698\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6705 - auc: 0.8782 - loss: 0.1829\n",
      "Epoch 7: val_auc improved from 0.89074 to 0.89196, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 279ms/step - accuracy: 0.6705 - auc: 0.8782 - loss: 0.1829 - val_accuracy: 0.6695 - val_auc: 0.8920 - val_loss: 0.1696\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6655 - auc: 0.8785 - loss: 0.1858\n",
      "Epoch 8: val_auc improved from 0.89196 to 0.89602, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 282ms/step - accuracy: 0.6655 - auc: 0.8785 - loss: 0.1858 - val_accuracy: 0.6695 - val_auc: 0.8960 - val_loss: 0.1701\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6710 - auc: 0.8786 - loss: 0.1898\n",
      "Epoch 9: val_auc did not improve from 0.89602\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 285ms/step - accuracy: 0.6710 - auc: 0.8786 - loss: 0.1898 - val_accuracy: 0.6695 - val_auc: 0.8936 - val_loss: 0.1687\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6681 - auc: 0.8825 - loss: 0.1771\n",
      "Epoch 10: val_auc did not improve from 0.89602\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 284ms/step - accuracy: 0.6681 - auc: 0.8825 - loss: 0.1771 - val_accuracy: 0.6695 - val_auc: 0.8912 - val_loss: 0.1686\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6670 - auc: 0.8795 - loss: 0.1904\n",
      "Epoch 11: val_auc did not improve from 0.89602\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6670 - auc: 0.8795 - loss: 0.1903 - val_accuracy: 0.6695 - val_auc: 0.8919 - val_loss: 0.1687\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5732 - auc: 0.8584 - loss: 0.2340\n",
      "Epoch 1: val_auc improved from -inf to 0.66002, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 1s/step - accuracy: 0.5734 - auc: 0.8585 - loss: 0.2339 - val_accuracy: 0.1098 - val_auc: 0.6600 - val_loss: 1.0863 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6664 - auc: 0.9182 - loss: 0.1601\n",
      "Epoch 2: val_auc did not improve from 0.66002\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.6664 - auc: 0.9182 - loss: 0.1601 - val_accuracy: 0.1153 - val_auc: 0.4871 - val_loss: 1.4785 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6863 - auc: 0.9353 - loss: 0.1412\n",
      "Epoch 3: val_auc improved from 0.66002 to 0.86383, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.6862 - auc: 0.9353 - loss: 0.1412 - val_accuracy: 0.5816 - val_auc: 0.8638 - val_loss: 0.2647 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7039 - auc: 0.9440 - loss: 0.1373\n",
      "Epoch 4: val_auc improved from 0.86383 to 0.92219, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.7039 - auc: 0.9440 - loss: 0.1373 - val_accuracy: 0.6870 - val_auc: 0.9222 - val_loss: 0.1577 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7261 - auc: 0.9515 - loss: 0.1237\n",
      "Epoch 5: val_auc improved from 0.92219 to 0.95901, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.7261 - auc: 0.9516 - loss: 0.1237 - val_accuracy: 0.7469 - val_auc: 0.9590 - val_loss: 0.1041 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7350 - auc: 0.9574 - loss: 0.1126\n",
      "Epoch 6: val_auc improved from 0.95901 to 0.96432, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.7350 - auc: 0.9574 - loss: 0.1126 - val_accuracy: 0.7629 - val_auc: 0.9643 - val_loss: 0.0926 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7558 - auc: 0.9616 - loss: 0.1026\n",
      "Epoch 7: val_auc improved from 0.96432 to 0.96816, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.7558 - auc: 0.9616 - loss: 0.1026 - val_accuracy: 0.7828 - val_auc: 0.9682 - val_loss: 0.0874 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7765 - auc: 0.9669 - loss: 0.0928\n",
      "Epoch 8: val_auc improved from 0.96816 to 0.96883, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.7765 - auc: 0.9669 - loss: 0.0928 - val_accuracy: 0.7853 - val_auc: 0.9688 - val_loss: 0.0857 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7915 - auc: 0.9724 - loss: 0.0844\n",
      "Epoch 9: val_auc improved from 0.96883 to 0.97164, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.7915 - auc: 0.9724 - loss: 0.0844 - val_accuracy: 0.7958 - val_auc: 0.9716 - val_loss: 0.0811 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7951 - auc: 0.9747 - loss: 0.0785\n",
      "Epoch 10: val_auc did not improve from 0.97164\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.7951 - auc: 0.9747 - loss: 0.0785 - val_accuracy: 0.8023 - val_auc: 0.9711 - val_loss: 0.0799 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8186 - auc: 0.9785 - loss: 0.0709\n",
      "Epoch 11: val_auc improved from 0.97164 to 0.97354, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8186 - auc: 0.9785 - loss: 0.0709 - val_accuracy: 0.8003 - val_auc: 0.9735 - val_loss: 0.0768 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8215 - auc: 0.9804 - loss: 0.0654\n",
      "Epoch 12: val_auc improved from 0.97354 to 0.97517, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.8215 - auc: 0.9804 - loss: 0.0654 - val_accuracy: 0.8098 - val_auc: 0.9752 - val_loss: 0.0739 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8310 - auc: 0.9824 - loss: 0.0612\n",
      "Epoch 13: val_auc improved from 0.97517 to 0.97566, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.8310 - auc: 0.9824 - loss: 0.0612 - val_accuracy: 0.8158 - val_auc: 0.9757 - val_loss: 0.0729 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8502 - auc: 0.9868 - loss: 0.0513\n",
      "Epoch 14: val_auc did not improve from 0.97566\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.8502 - auc: 0.9868 - loss: 0.0513 - val_accuracy: 0.8068 - val_auc: 0.9720 - val_loss: 0.0806 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8578 - auc: 0.9869 - loss: 0.0497\n",
      "Epoch 15: val_auc improved from 0.97566 to 0.97670, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8578 - auc: 0.9869 - loss: 0.0497 - val_accuracy: 0.8213 - val_auc: 0.9767 - val_loss: 0.0731 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8688 - auc: 0.9886 - loss: 0.0505\n",
      "Epoch 16: val_auc did not improve from 0.97670\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.8688 - auc: 0.9886 - loss: 0.0505 - val_accuracy: 0.8218 - val_auc: 0.9754 - val_loss: 0.0769 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8755 - auc: 0.9903 - loss: 0.0419\n",
      "Epoch 17: val_auc improved from 0.97670 to 0.97763, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.8755 - auc: 0.9903 - loss: 0.0419 - val_accuracy: 0.8213 - val_auc: 0.9776 - val_loss: 0.0714 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8906 - auc: 0.9922 - loss: 0.0356\n",
      "Epoch 18: val_auc improved from 0.97763 to 0.97853, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8906 - auc: 0.9922 - loss: 0.0356 - val_accuracy: 0.8188 - val_auc: 0.9785 - val_loss: 0.0732 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8926 - auc: 0.9923 - loss: 0.0347\n",
      "Epoch 19: val_auc improved from 0.97853 to 0.97874, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.8926 - auc: 0.9923 - loss: 0.0347 - val_accuracy: 0.8298 - val_auc: 0.9787 - val_loss: 0.0717 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8940 - auc: 0.9932 - loss: 0.0323\n",
      "Epoch 20: val_auc did not improve from 0.97874\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.8940 - auc: 0.9932 - loss: 0.0323 - val_accuracy: 0.8178 - val_auc: 0.9770 - val_loss: 0.0755 - learning_rate: 1.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9009 - auc: 0.9941 - loss: 0.0295\n",
      "Epoch 21: val_auc did not improve from 0.97874\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.9009 - auc: 0.9941 - loss: 0.0295 - val_accuracy: 0.8193 - val_auc: 0.9760 - val_loss: 0.0773 - learning_rate: 1.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9121 - auc: 0.9951 - loss: 0.0285\n",
      "Epoch 22: val_auc improved from 0.97874 to 0.97972, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.9121 - auc: 0.9951 - loss: 0.0285 - val_accuracy: 0.8377 - val_auc: 0.9797 - val_loss: 0.0705 - learning_rate: 1.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9256 - auc: 0.9962 - loss: 0.0230\n",
      "Epoch 23: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 1s/step - accuracy: 0.9256 - auc: 0.9962 - loss: 0.0230 - val_accuracy: 0.8258 - val_auc: 0.9757 - val_loss: 0.0835 - learning_rate: 1.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9267 - auc: 0.9966 - loss: 0.0228\n",
      "Epoch 24: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.9267 - auc: 0.9966 - loss: 0.0228 - val_accuracy: 0.8243 - val_auc: 0.9772 - val_loss: 0.0776 - learning_rate: 1.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9255 - auc: 0.9962 - loss: 0.0229\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 25: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9255 - auc: 0.9963 - loss: 0.0229 - val_accuracy: 0.8213 - val_auc: 0.9770 - val_loss: 0.0795 - learning_rate: 1.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9370 - auc: 0.9972 - loss: 0.0179\n",
      "Epoch 26: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.9370 - auc: 0.9972 - loss: 0.0179 - val_accuracy: 0.8273 - val_auc: 0.9766 - val_loss: 0.0812 - learning_rate: 1.0000e-06\n",
      "Epoch 27/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9427 - auc: 0.9978 - loss: 0.0159\n",
      "Epoch 27: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.9427 - auc: 0.9978 - loss: 0.0159 - val_accuracy: 0.8288 - val_auc: 0.9774 - val_loss: 0.0805 - learning_rate: 1.0000e-06\n",
      "Epoch 28/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9458 - auc: 0.9979 - loss: 0.0166\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 28: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 1s/step - accuracy: 0.9458 - auc: 0.9979 - loss: 0.0166 - val_accuracy: 0.8313 - val_auc: 0.9774 - val_loss: 0.0806 - learning_rate: 1.0000e-06\n",
      "Epoch 29/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9477 - auc: 0.9980 - loss: 0.0148\n",
      "Epoch 29: val_auc did not improve from 0.97972\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9477 - auc: 0.9980 - loss: 0.0148 - val_accuracy: 0.8303 - val_auc: 0.9770 - val_loss: 0.0814 - learning_rate: 1.0000e-07\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "FOLD 1 - Loss: 0.0705, Accuracy: 0.8377, AUC: 0.9797\n",
      "\n",
      "\n",
      "===== FOLD 2/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6339 - auc: 0.8481 - loss: 0.2196\n",
      "Epoch 1: val_auc improved from -inf to 0.87037, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 308ms/step - accuracy: 0.6340 - auc: 0.8482 - loss: 0.2195 - val_accuracy: 0.6695 - val_auc: 0.8704 - val_loss: 0.1731\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.6696 - auc: 0.8681 - loss: 0.1996\n",
      "Epoch 2: val_auc improved from 0.87037 to 0.87622, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 294ms/step - accuracy: 0.6696 - auc: 0.8682 - loss: 0.1995 - val_accuracy: 0.6695 - val_auc: 0.8762 - val_loss: 0.1739\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.6690 - auc: 0.8728 - loss: 0.1922\n",
      "Epoch 3: val_auc improved from 0.87622 to 0.87935, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 297ms/step - accuracy: 0.6690 - auc: 0.8728 - loss: 0.1921 - val_accuracy: 0.6695 - val_auc: 0.8793 - val_loss: 0.1726\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.6788 - auc: 0.8772 - loss: 0.1776\n",
      "Epoch 4: val_auc improved from 0.87935 to 0.88149, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 288ms/step - accuracy: 0.6788 - auc: 0.8772 - loss: 0.1776 - val_accuracy: 0.6695 - val_auc: 0.8815 - val_loss: 0.1737\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.6666 - auc: 0.8724 - loss: 0.1878\n",
      "Epoch 5: val_auc improved from 0.88149 to 0.88469, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 296ms/step - accuracy: 0.6666 - auc: 0.8724 - loss: 0.1878 - val_accuracy: 0.6695 - val_auc: 0.8847 - val_loss: 0.1709\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6785 - auc: 0.8813 - loss: 0.1710\n",
      "Epoch 6: val_auc improved from 0.88469 to 0.89261, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 271ms/step - accuracy: 0.6785 - auc: 0.8813 - loss: 0.1711 - val_accuracy: 0.6695 - val_auc: 0.8926 - val_loss: 0.1712\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6724 - auc: 0.8790 - loss: 0.1765\n",
      "Epoch 7: val_auc improved from 0.89261 to 0.89440, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 277ms/step - accuracy: 0.6723 - auc: 0.8790 - loss: 0.1765 - val_accuracy: 0.6695 - val_auc: 0.8944 - val_loss: 0.1704\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6625 - auc: 0.8741 - loss: 0.1964\n",
      "Epoch 8: val_auc did not improve from 0.89440\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6625 - auc: 0.8741 - loss: 0.1963 - val_accuracy: 0.6695 - val_auc: 0.8908 - val_loss: 0.1699\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6697 - auc: 0.8780 - loss: 0.1846\n",
      "Epoch 9: val_auc did not improve from 0.89440\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.6697 - auc: 0.8780 - loss: 0.1846 - val_accuracy: 0.6695 - val_auc: 0.8912 - val_loss: 0.1707\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6703 - auc: 0.8788 - loss: 0.1831\n",
      "Epoch 10: val_auc improved from 0.89440 to 0.89560, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 286ms/step - accuracy: 0.6703 - auc: 0.8788 - loss: 0.1831 - val_accuracy: 0.6695 - val_auc: 0.8956 - val_loss: 0.1697\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.6793 - auc: 0.8817 - loss: 0.1798\n",
      "Epoch 11: val_auc did not improve from 0.89560\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 286ms/step - accuracy: 0.6793 - auc: 0.8817 - loss: 0.1798 - val_accuracy: 0.6690 - val_auc: 0.8910 - val_loss: 0.1699\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.6720 - auc: 0.8810 - loss: 0.1841\n",
      "Epoch 12: val_auc did not improve from 0.89560\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 291ms/step - accuracy: 0.6720 - auc: 0.8810 - loss: 0.1841 - val_accuracy: 0.6695 - val_auc: 0.8916 - val_loss: 0.1696\n",
      "Epoch 13/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6702 - auc: 0.8792 - loss: 0.1850\n",
      "Epoch 13: val_auc did not improve from 0.89560\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.6702 - auc: 0.8792 - loss: 0.1850 - val_accuracy: 0.6690 - val_auc: 0.8942 - val_loss: 0.1690\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5484 - auc: 0.8374 - loss: 0.3219\n",
      "Epoch 1: val_auc improved from -inf to 0.83771, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.5485 - auc: 0.8375 - loss: 0.3218 - val_accuracy: 0.6350 - val_auc: 0.8377 - val_loss: 0.8292 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6414 - auc: 0.9024 - loss: 0.1968\n",
      "Epoch 2: val_auc improved from 0.83771 to 0.84628, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.6414 - auc: 0.9024 - loss: 0.1967 - val_accuracy: 0.5197 - val_auc: 0.8463 - val_loss: 0.5104 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6690 - auc: 0.9209 - loss: 0.1720\n",
      "Epoch 3: val_auc did not improve from 0.84628\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.6691 - auc: 0.9209 - loss: 0.1720 - val_accuracy: 0.3035 - val_auc: 0.7781 - val_loss: 0.3877 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6982 - auc: 0.9356 - loss: 0.1427\n",
      "Epoch 4: val_auc improved from 0.84628 to 0.91177, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 1s/step - accuracy: 0.6982 - auc: 0.9356 - loss: 0.1427 - val_accuracy: 0.6745 - val_auc: 0.9118 - val_loss: 0.2001 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7095 - auc: 0.9433 - loss: 0.1321\n",
      "Epoch 5: val_auc improved from 0.91177 to 0.94834, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 1s/step - accuracy: 0.7095 - auc: 0.9433 - loss: 0.1321 - val_accuracy: 0.7344 - val_auc: 0.9483 - val_loss: 0.1208 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7252 - auc: 0.9488 - loss: 0.1244\n",
      "Epoch 6: val_auc improved from 0.94834 to 0.95890, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.7252 - auc: 0.9488 - loss: 0.1244 - val_accuracy: 0.7499 - val_auc: 0.9589 - val_loss: 0.1041 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7355 - auc: 0.9539 - loss: 0.1197\n",
      "Epoch 7: val_auc improved from 0.95890 to 0.96214, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.7355 - auc: 0.9539 - loss: 0.1197 - val_accuracy: 0.7589 - val_auc: 0.9621 - val_loss: 0.0990 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7493 - auc: 0.9593 - loss: 0.1083\n",
      "Epoch 8: val_auc improved from 0.96214 to 0.96579, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.7493 - auc: 0.9593 - loss: 0.1083 - val_accuracy: 0.7713 - val_auc: 0.9658 - val_loss: 0.0918 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7630 - auc: 0.9640 - loss: 0.1032\n",
      "Epoch 9: val_auc improved from 0.96579 to 0.96865, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.7630 - auc: 0.9640 - loss: 0.1032 - val_accuracy: 0.7818 - val_auc: 0.9687 - val_loss: 0.0872 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7845 - auc: 0.9701 - loss: 0.0878\n",
      "Epoch 10: val_auc improved from 0.96865 to 0.97167, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.7845 - auc: 0.9701 - loss: 0.0878 - val_accuracy: 0.8043 - val_auc: 0.9717 - val_loss: 0.0807 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7929 - auc: 0.9739 - loss: 0.0787\n",
      "Epoch 11: val_auc improved from 0.97167 to 0.97336, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.7929 - auc: 0.9739 - loss: 0.0787 - val_accuracy: 0.8073 - val_auc: 0.9734 - val_loss: 0.0773 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7978 - auc: 0.9748 - loss: 0.0818\n",
      "Epoch 12: val_auc improved from 0.97336 to 0.97597, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.7978 - auc: 0.9748 - loss: 0.0818 - val_accuracy: 0.8138 - val_auc: 0.9760 - val_loss: 0.0715 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8186 - auc: 0.9788 - loss: 0.0692\n",
      "Epoch 13: val_auc did not improve from 0.97597\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.8186 - auc: 0.9788 - loss: 0.0692 - val_accuracy: 0.8133 - val_auc: 0.9758 - val_loss: 0.0712 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8257 - auc: 0.9818 - loss: 0.0645\n",
      "Epoch 14: val_auc improved from 0.97597 to 0.97776, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8258 - auc: 0.9818 - loss: 0.0645 - val_accuracy: 0.8218 - val_auc: 0.9778 - val_loss: 0.0685 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8383 - auc: 0.9839 - loss: 0.0601\n",
      "Epoch 15: val_auc did not improve from 0.97776\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.8383 - auc: 0.9839 - loss: 0.0601 - val_accuracy: 0.8168 - val_auc: 0.9767 - val_loss: 0.0708 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8349 - auc: 0.9833 - loss: 0.0609\n",
      "Epoch 16: val_auc improved from 0.97776 to 0.97932, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.8350 - auc: 0.9833 - loss: 0.0609 - val_accuracy: 0.8293 - val_auc: 0.9793 - val_loss: 0.0664 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8627 - auc: 0.9872 - loss: 0.0507\n",
      "Epoch 17: val_auc improved from 0.97932 to 0.97986, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8627 - auc: 0.9872 - loss: 0.0507 - val_accuracy: 0.8313 - val_auc: 0.9799 - val_loss: 0.0652 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8680 - auc: 0.9893 - loss: 0.0449\n",
      "Epoch 18: val_auc did not improve from 0.97986\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.8680 - auc: 0.9893 - loss: 0.0449 - val_accuracy: 0.8333 - val_auc: 0.9786 - val_loss: 0.0680 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8879 - auc: 0.9913 - loss: 0.0378\n",
      "Epoch 19: val_auc did not improve from 0.97986\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.8878 - auc: 0.9913 - loss: 0.0378 - val_accuracy: 0.8208 - val_auc: 0.9777 - val_loss: 0.0688 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8795 - auc: 0.9907 - loss: 0.0416\n",
      "Epoch 20: val_auc improved from 0.97986 to 0.98101, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.8795 - auc: 0.9907 - loss: 0.0416 - val_accuracy: 0.8303 - val_auc: 0.9810 - val_loss: 0.0650 - learning_rate: 1.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8952 - auc: 0.9931 - loss: 0.0329\n",
      "Epoch 21: val_auc did not improve from 0.98101\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8952 - auc: 0.9931 - loss: 0.0329 - val_accuracy: 0.8333 - val_auc: 0.9797 - val_loss: 0.0695 - learning_rate: 1.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9019 - auc: 0.9935 - loss: 0.0308\n",
      "Epoch 22: val_auc did not improve from 0.98101\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.9019 - auc: 0.9935 - loss: 0.0308 - val_accuracy: 0.8293 - val_auc: 0.9801 - val_loss: 0.0670 - learning_rate: 1.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9083 - auc: 0.9942 - loss: 0.0293\n",
      "Epoch 23: val_auc improved from 0.98101 to 0.98241, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.9083 - auc: 0.9942 - loss: 0.0293 - val_accuracy: 0.8517 - val_auc: 0.9824 - val_loss: 0.0659 - learning_rate: 1.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9063 - auc: 0.9944 - loss: 0.0289\n",
      "Epoch 24: val_auc did not improve from 0.98241\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.9063 - auc: 0.9944 - loss: 0.0289 - val_accuracy: 0.8402 - val_auc: 0.9796 - val_loss: 0.0708 - learning_rate: 1.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9136 - auc: 0.9954 - loss: 0.0252\n",
      "Epoch 25: val_auc did not improve from 0.98241\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.9136 - auc: 0.9954 - loss: 0.0252 - val_accuracy: 0.8452 - val_auc: 0.9811 - val_loss: 0.0707 - learning_rate: 1.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9297 - auc: 0.9966 - loss: 0.0211\n",
      "Epoch 26: val_auc improved from 0.98241 to 0.98264, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.9297 - auc: 0.9966 - loss: 0.0211 - val_accuracy: 0.8567 - val_auc: 0.9826 - val_loss: 0.0670 - learning_rate: 1.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9333 - auc: 0.9970 - loss: 0.0194\n",
      "Epoch 27: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.9333 - auc: 0.9970 - loss: 0.0194 - val_accuracy: 0.8063 - val_auc: 0.9735 - val_loss: 0.0884 - learning_rate: 1.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9410 - auc: 0.9973 - loss: 0.0180\n",
      "Epoch 28: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.9410 - auc: 0.9973 - loss: 0.0180 - val_accuracy: 0.8587 - val_auc: 0.9808 - val_loss: 0.0733 - learning_rate: 1.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9426 - auc: 0.9975 - loss: 0.0174\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 29: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9426 - auc: 0.9975 - loss: 0.0174 - val_accuracy: 0.8123 - val_auc: 0.9736 - val_loss: 0.0913 - learning_rate: 1.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9414 - auc: 0.9974 - loss: 0.0172\n",
      "Epoch 30: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9414 - auc: 0.9974 - loss: 0.0172 - val_accuracy: 0.8333 - val_auc: 0.9778 - val_loss: 0.0783 - learning_rate: 1.0000e-06\n",
      "Epoch 31/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9469 - auc: 0.9982 - loss: 0.0137\n",
      "Epoch 31: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9469 - auc: 0.9982 - loss: 0.0137 - val_accuracy: 0.8323 - val_auc: 0.9778 - val_loss: 0.0790 - learning_rate: 1.0000e-06\n",
      "Epoch 32/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9560 - auc: 0.9984 - loss: 0.0131\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 32: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.9560 - auc: 0.9984 - loss: 0.0131 - val_accuracy: 0.8293 - val_auc: 0.9777 - val_loss: 0.0813 - learning_rate: 1.0000e-06\n",
      "Epoch 33/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9564 - auc: 0.9986 - loss: 0.0127\n",
      "Epoch 33: val_auc did not improve from 0.98264\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 1s/step - accuracy: 0.9564 - auc: 0.9986 - loss: 0.0127 - val_accuracy: 0.8308 - val_auc: 0.9780 - val_loss: 0.0799 - learning_rate: 1.0000e-07\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "FOLD 2 - Loss: 0.0670, Accuracy: 0.8567, AUC: 0.9826\n",
      "\n",
      "\n",
      "===== FOLD 3/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       891\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      113\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       222\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       29\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6400 - auc: 0.8571 - loss: 0.2082\n",
      "Epoch 1: val_auc improved from -inf to 0.87308, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 299ms/step - accuracy: 0.6401 - auc: 0.8572 - loss: 0.2081 - val_accuracy: 0.6695 - val_auc: 0.8731 - val_loss: 0.1731\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6726 - auc: 0.8743 - loss: 0.1883\n",
      "Epoch 2: val_auc improved from 0.87308 to 0.88264, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6726 - auc: 0.8743 - loss: 0.1883 - val_accuracy: 0.6695 - val_auc: 0.8826 - val_loss: 0.1735\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.6721 - auc: 0.8754 - loss: 0.1885\n",
      "Epoch 3: val_auc improved from 0.88264 to 0.88603, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 299ms/step - accuracy: 0.6721 - auc: 0.8754 - loss: 0.1885 - val_accuracy: 0.6695 - val_auc: 0.8860 - val_loss: 0.1710\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6718 - auc: 0.8811 - loss: 0.1756\n",
      "Epoch 4: val_auc improved from 0.88603 to 0.88801, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 280ms/step - accuracy: 0.6718 - auc: 0.8811 - loss: 0.1756 - val_accuracy: 0.6695 - val_auc: 0.8880 - val_loss: 0.1712\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6740 - auc: 0.8808 - loss: 0.1799\n",
      "Epoch 5: val_auc did not improve from 0.88801\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6740 - auc: 0.8808 - loss: 0.1799 - val_accuracy: 0.6700 - val_auc: 0.8876 - val_loss: 0.1703\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6751 - auc: 0.8811 - loss: 0.1805\n",
      "Epoch 6: val_auc improved from 0.88801 to 0.88913, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 280ms/step - accuracy: 0.6751 - auc: 0.8811 - loss: 0.1805 - val_accuracy: 0.6695 - val_auc: 0.8891 - val_loss: 0.1697\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6740 - auc: 0.8812 - loss: 0.1852\n",
      "Epoch 7: val_auc did not improve from 0.88913\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 281ms/step - accuracy: 0.6740 - auc: 0.8812 - loss: 0.1851 - val_accuracy: 0.6695 - val_auc: 0.8891 - val_loss: 0.1698\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6674 - auc: 0.8831 - loss: 0.1822\n",
      "Epoch 8: val_auc improved from 0.88913 to 0.89003, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 279ms/step - accuracy: 0.6674 - auc: 0.8831 - loss: 0.1822 - val_accuracy: 0.6695 - val_auc: 0.8900 - val_loss: 0.1707\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6624 - auc: 0.8792 - loss: 0.1927\n",
      "Epoch 9: val_auc improved from 0.89003 to 0.89438, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 279ms/step - accuracy: 0.6624 - auc: 0.8792 - loss: 0.1927 - val_accuracy: 0.6695 - val_auc: 0.8944 - val_loss: 0.1685\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6636 - auc: 0.8824 - loss: 0.1875\n",
      "Epoch 10: val_auc improved from 0.89438 to 0.89619, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 269ms/step - accuracy: 0.6637 - auc: 0.8824 - loss: 0.1875 - val_accuracy: 0.6690 - val_auc: 0.8962 - val_loss: 0.1682\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6761 - auc: 0.8873 - loss: 0.1774\n",
      "Epoch 11: val_auc did not improve from 0.89619\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 273ms/step - accuracy: 0.6761 - auc: 0.8873 - loss: 0.1775 - val_accuracy: 0.6690 - val_auc: 0.8905 - val_loss: 0.1689\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.6659 - auc: 0.8842 - loss: 0.1802\n",
      "Epoch 12: val_auc did not improve from 0.89619\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 291ms/step - accuracy: 0.6659 - auc: 0.8842 - loss: 0.1802 - val_accuracy: 0.6695 - val_auc: 0.8913 - val_loss: 0.1692\n",
      "Epoch 13/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6665 - auc: 0.8817 - loss: 0.1913\n",
      "Epoch 13: val_auc did not improve from 0.89619\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 292ms/step - accuracy: 0.6665 - auc: 0.8818 - loss: 0.1912 - val_accuracy: 0.6690 - val_auc: 0.8930 - val_loss: 0.1680\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4826 - auc: 0.7977 - loss: 0.5679\n",
      "Epoch 1: val_auc improved from -inf to 0.48289, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 1s/step - accuracy: 0.4829 - auc: 0.7978 - loss: 0.5674 - val_accuracy: 0.1108 - val_auc: 0.4829 - val_loss: 2.2456 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6363 - auc: 0.9037 - loss: 0.2486\n",
      "Epoch 2: val_auc did not improve from 0.48289\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.6364 - auc: 0.9037 - loss: 0.2485 - val_accuracy: 0.1113 - val_auc: 0.4791 - val_loss: 2.4296 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6623 - auc: 0.9207 - loss: 0.1912\n",
      "Epoch 3: val_auc improved from 0.48289 to 0.48550, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.6623 - auc: 0.9208 - loss: 0.1911 - val_accuracy: 0.1308 - val_auc: 0.4855 - val_loss: 1.4355 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6770 - auc: 0.9332 - loss: 0.1561\n",
      "Epoch 4: val_auc improved from 0.48550 to 0.90989, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.6771 - auc: 0.9333 - loss: 0.1560 - val_accuracy: 0.6730 - val_auc: 0.9099 - val_loss: 0.2418 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7108 - auc: 0.9477 - loss: 0.1324\n",
      "Epoch 5: val_auc improved from 0.90989 to 0.95101, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.7108 - auc: 0.9477 - loss: 0.1324 - val_accuracy: 0.7259 - val_auc: 0.9510 - val_loss: 0.1255 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7270 - auc: 0.9538 - loss: 0.1234\n",
      "Epoch 6: val_auc improved from 0.95101 to 0.95988, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.7270 - auc: 0.9538 - loss: 0.1234 - val_accuracy: 0.7444 - val_auc: 0.9599 - val_loss: 0.1052 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7458 - auc: 0.9609 - loss: 0.1029\n",
      "Epoch 7: val_auc improved from 0.95988 to 0.96409, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.7458 - auc: 0.9609 - loss: 0.1029 - val_accuracy: 0.7599 - val_auc: 0.9641 - val_loss: 0.0960 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7643 - auc: 0.9662 - loss: 0.0998\n",
      "Epoch 8: val_auc improved from 0.96409 to 0.96717, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.7644 - auc: 0.9662 - loss: 0.0998 - val_accuracy: 0.7758 - val_auc: 0.9672 - val_loss: 0.0894 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7705 - auc: 0.9707 - loss: 0.0859\n",
      "Epoch 9: val_auc improved from 0.96717 to 0.96944, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.7705 - auc: 0.9707 - loss: 0.0860 - val_accuracy: 0.7808 - val_auc: 0.9694 - val_loss: 0.0855 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7896 - auc: 0.9727 - loss: 0.0849\n",
      "Epoch 10: val_auc improved from 0.96944 to 0.97178, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.7896 - auc: 0.9727 - loss: 0.0849 - val_accuracy: 0.7858 - val_auc: 0.9718 - val_loss: 0.0786 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7997 - auc: 0.9764 - loss: 0.0731\n",
      "Epoch 11: val_auc improved from 0.97178 to 0.97346, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.7997 - auc: 0.9763 - loss: 0.0731 - val_accuracy: 0.7863 - val_auc: 0.9735 - val_loss: 0.0758 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8151 - auc: 0.9801 - loss: 0.0649\n",
      "Epoch 12: val_auc improved from 0.97346 to 0.97532, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.8151 - auc: 0.9801 - loss: 0.0649 - val_accuracy: 0.8033 - val_auc: 0.9753 - val_loss: 0.0734 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8176 - auc: 0.9805 - loss: 0.0671\n",
      "Epoch 13: val_auc improved from 0.97532 to 0.97584, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.8176 - auc: 0.9805 - loss: 0.0671 - val_accuracy: 0.8073 - val_auc: 0.9758 - val_loss: 0.0724 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8325 - auc: 0.9828 - loss: 0.0622\n",
      "Epoch 14: val_auc improved from 0.97584 to 0.97681, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8325 - auc: 0.9828 - loss: 0.0622 - val_accuracy: 0.8148 - val_auc: 0.9768 - val_loss: 0.0698 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8432 - auc: 0.9846 - loss: 0.0574\n",
      "Epoch 15: val_auc did not improve from 0.97681\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8432 - auc: 0.9846 - loss: 0.0574 - val_accuracy: 0.8078 - val_auc: 0.9766 - val_loss: 0.0707 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8478 - auc: 0.9854 - loss: 0.0522\n",
      "Epoch 16: val_auc improved from 0.97681 to 0.97774, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8479 - auc: 0.9854 - loss: 0.0522 - val_accuracy: 0.8178 - val_auc: 0.9777 - val_loss: 0.0697 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8613 - auc: 0.9884 - loss: 0.0451\n",
      "Epoch 17: val_auc did not improve from 0.97774\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8613 - auc: 0.9884 - loss: 0.0451 - val_accuracy: 0.8078 - val_auc: 0.9772 - val_loss: 0.0697 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8691 - auc: 0.9896 - loss: 0.0414\n",
      "Epoch 18: val_auc improved from 0.97774 to 0.97922, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8691 - auc: 0.9896 - loss: 0.0414 - val_accuracy: 0.8223 - val_auc: 0.9792 - val_loss: 0.0669 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8781 - auc: 0.9912 - loss: 0.0388\n",
      "Epoch 19: val_auc improved from 0.97922 to 0.98009, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.8781 - auc: 0.9912 - loss: 0.0388 - val_accuracy: 0.8303 - val_auc: 0.9801 - val_loss: 0.0676 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8819 - auc: 0.9922 - loss: 0.0351\n",
      "Epoch 20: val_auc improved from 0.98009 to 0.98053, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.8820 - auc: 0.9922 - loss: 0.0351 - val_accuracy: 0.8397 - val_auc: 0.9805 - val_loss: 0.0663 - learning_rate: 1.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8933 - auc: 0.9929 - loss: 0.0337\n",
      "Epoch 21: val_auc did not improve from 0.98053\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8934 - auc: 0.9929 - loss: 0.0337 - val_accuracy: 0.8293 - val_auc: 0.9786 - val_loss: 0.0711 - learning_rate: 1.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9077 - auc: 0.9941 - loss: 0.0290\n",
      "Epoch 22: val_auc did not improve from 0.98053\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.9077 - auc: 0.9941 - loss: 0.0290 - val_accuracy: 0.8158 - val_auc: 0.9774 - val_loss: 0.0766 - learning_rate: 1.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9079 - auc: 0.9949 - loss: 0.0255\n",
      "Epoch 23: val_auc improved from 0.98053 to 0.98095, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.9079 - auc: 0.9949 - loss: 0.0255 - val_accuracy: 0.8397 - val_auc: 0.9810 - val_loss: 0.0681 - learning_rate: 1.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9101 - auc: 0.9954 - loss: 0.0239\n",
      "Epoch 24: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.9101 - auc: 0.9954 - loss: 0.0239 - val_accuracy: 0.8432 - val_auc: 0.9802 - val_loss: 0.0741 - learning_rate: 1.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9290 - auc: 0.9965 - loss: 0.0211\n",
      "Epoch 25: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.9290 - auc: 0.9965 - loss: 0.0211 - val_accuracy: 0.8033 - val_auc: 0.9741 - val_loss: 0.0874 - learning_rate: 1.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9261 - auc: 0.9962 - loss: 0.0232\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 26: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.9262 - auc: 0.9962 - loss: 0.0232 - val_accuracy: 0.8223 - val_auc: 0.9781 - val_loss: 0.0771 - learning_rate: 1.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9362 - auc: 0.9972 - loss: 0.0172\n",
      "Epoch 27: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.9362 - auc: 0.9972 - loss: 0.0172 - val_accuracy: 0.8412 - val_auc: 0.9804 - val_loss: 0.0715 - learning_rate: 1.0000e-06\n",
      "Epoch 28/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9387 - auc: 0.9974 - loss: 0.0165\n",
      "Epoch 28: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.9386 - auc: 0.9974 - loss: 0.0165 - val_accuracy: 0.8432 - val_auc: 0.9807 - val_loss: 0.0721 - learning_rate: 1.0000e-06\n",
      "Epoch 29/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9350 - auc: 0.9969 - loss: 0.0192\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 29: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.9350 - auc: 0.9969 - loss: 0.0192 - val_accuracy: 0.8447 - val_auc: 0.9804 - val_loss: 0.0728 - learning_rate: 1.0000e-06\n",
      "Epoch 30/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9389 - auc: 0.9973 - loss: 0.0169\n",
      "Epoch 30: val_auc did not improve from 0.98095\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 1s/step - accuracy: 0.9389 - auc: 0.9973 - loss: 0.0169 - val_accuracy: 0.8447 - val_auc: 0.9805 - val_loss: 0.0726 - learning_rate: 1.0000e-07\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "FOLD 3 - Loss: 0.0681, Accuracy: 0.8397, AUC: 0.9810\n",
      "\n",
      "\n",
      "===== FOLD 4/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       891\n",
      "bkl       879\n",
      "bcc       412\n",
      "akiec     261\n",
      "vasc      113\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       222\n",
      "bkl       220\n",
      "bcc       102\n",
      "akiec      66\n",
      "vasc       29\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6511 - auc: 0.8583 - loss: 0.2027\n",
      "Epoch 1: val_auc improved from -inf to 0.87860, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 374ms/step - accuracy: 0.6512 - auc: 0.8583 - loss: 0.2027 - val_accuracy: 0.6695 - val_auc: 0.8786 - val_loss: 0.1724\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6737 - auc: 0.8747 - loss: 0.1860\n",
      "Epoch 2: val_auc improved from 0.87860 to 0.88406, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 285ms/step - accuracy: 0.6737 - auc: 0.8747 - loss: 0.1860 - val_accuracy: 0.6695 - val_auc: 0.8841 - val_loss: 0.1726\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6583 - auc: 0.8699 - loss: 0.2001\n",
      "Epoch 3: val_auc improved from 0.88406 to 0.88593, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 283ms/step - accuracy: 0.6584 - auc: 0.8700 - loss: 0.2000 - val_accuracy: 0.6695 - val_auc: 0.8859 - val_loss: 0.1720\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6753 - auc: 0.8801 - loss: 0.1730\n",
      "Epoch 4: val_auc improved from 0.88593 to 0.89109, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 277ms/step - accuracy: 0.6753 - auc: 0.8801 - loss: 0.1730 - val_accuracy: 0.6695 - val_auc: 0.8911 - val_loss: 0.1708\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6710 - auc: 0.8764 - loss: 0.1891\n",
      "Epoch 5: val_auc did not improve from 0.89109\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 278ms/step - accuracy: 0.6709 - auc: 0.8764 - loss: 0.1891 - val_accuracy: 0.6695 - val_auc: 0.8911 - val_loss: 0.1703\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.6639 - auc: 0.8751 - loss: 0.1916\n",
      "Epoch 6: val_auc improved from 0.89109 to 0.89116, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 291ms/step - accuracy: 0.6639 - auc: 0.8751 - loss: 0.1916 - val_accuracy: 0.6695 - val_auc: 0.8912 - val_loss: 0.1699\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.6742 - auc: 0.8833 - loss: 0.1775\n",
      "Epoch 7: val_auc improved from 0.89116 to 0.89414, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 295ms/step - accuracy: 0.6742 - auc: 0.8833 - loss: 0.1775 - val_accuracy: 0.6695 - val_auc: 0.8941 - val_loss: 0.1705\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6656 - auc: 0.8810 - loss: 0.1863\n",
      "Epoch 8: val_auc did not improve from 0.89414\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.6657 - auc: 0.8810 - loss: 0.1863 - val_accuracy: 0.6695 - val_auc: 0.8904 - val_loss: 0.1693\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6706 - auc: 0.8849 - loss: 0.1780\n",
      "Epoch 9: val_auc improved from 0.89414 to 0.89732, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 277ms/step - accuracy: 0.6706 - auc: 0.8849 - loss: 0.1780 - val_accuracy: 0.6695 - val_auc: 0.8973 - val_loss: 0.1696\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6745 - auc: 0.8868 - loss: 0.1721\n",
      "Epoch 10: val_auc did not improve from 0.89732\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 276ms/step - accuracy: 0.6745 - auc: 0.8867 - loss: 0.1721 - val_accuracy: 0.6695 - val_auc: 0.8941 - val_loss: 0.1700\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6698 - auc: 0.8837 - loss: 0.1781\n",
      "Epoch 11: val_auc improved from 0.89732 to 0.89784, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 277ms/step - accuracy: 0.6698 - auc: 0.8837 - loss: 0.1781 - val_accuracy: 0.6695 - val_auc: 0.8978 - val_loss: 0.1679\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.6659 - auc: 0.8820 - loss: 0.1858\n",
      "Epoch 12: val_auc did not improve from 0.89784\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 273ms/step - accuracy: 0.6659 - auc: 0.8821 - loss: 0.1858 - val_accuracy: 0.6690 - val_auc: 0.8970 - val_loss: 0.1684\n",
      "Epoch 13/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6657 - auc: 0.8796 - loss: 0.1964\n",
      "Epoch 13: val_auc did not improve from 0.89784\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 285ms/step - accuracy: 0.6657 - auc: 0.8796 - loss: 0.1964 - val_accuracy: 0.6690 - val_auc: 0.8966 - val_loss: 0.1671\n",
      "Epoch 14/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6676 - auc: 0.8845 - loss: 0.1840\n",
      "Epoch 14: val_auc did not improve from 0.89784\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 272ms/step - accuracy: 0.6676 - auc: 0.8845 - loss: 0.1840 - val_accuracy: 0.6690 - val_auc: 0.8974 - val_loss: 0.1673\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5721 - auc: 0.8478 - loss: 0.4194\n",
      "Epoch 1: val_auc improved from -inf to 0.69881, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.5722 - auc: 0.8478 - loss: 0.4192 - val_accuracy: 0.1183 - val_auc: 0.6988 - val_loss: 0.6061 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6483 - auc: 0.9098 - loss: 0.2066\n",
      "Epoch 2: val_auc did not improve from 0.69881\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.6483 - auc: 0.9098 - loss: 0.2065 - val_accuracy: 0.1598 - val_auc: 0.6381 - val_loss: 1.1787 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.9240 - loss: 0.1679\n",
      "Epoch 3: val_auc improved from 0.69881 to 0.84002, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.9240 - loss: 0.1678 - val_accuracy: 0.6700 - val_auc: 0.8400 - val_loss: 0.8528 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6886 - auc: 0.9374 - loss: 0.1410\n",
      "Epoch 4: val_auc improved from 0.84002 to 0.91633, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.6886 - auc: 0.9374 - loss: 0.1410 - val_accuracy: 0.6795 - val_auc: 0.9163 - val_loss: 0.2001 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7163 - auc: 0.9491 - loss: 0.1224\n",
      "Epoch 5: val_auc improved from 0.91633 to 0.95705, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.7163 - auc: 0.9491 - loss: 0.1224 - val_accuracy: 0.7444 - val_auc: 0.9571 - val_loss: 0.1115 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7209 - auc: 0.9531 - loss: 0.1177\n",
      "Epoch 6: val_auc improved from 0.95705 to 0.96519, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.7209 - auc: 0.9531 - loss: 0.1176 - val_accuracy: 0.7693 - val_auc: 0.9652 - val_loss: 0.0951 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7567 - auc: 0.9611 - loss: 0.1046\n",
      "Epoch 7: val_auc improved from 0.96519 to 0.96817, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.7567 - auc: 0.9611 - loss: 0.1046 - val_accuracy: 0.7768 - val_auc: 0.9682 - val_loss: 0.0890 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7643 - auc: 0.9653 - loss: 0.0968\n",
      "Epoch 8: val_auc improved from 0.96817 to 0.97034, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 1s/step - accuracy: 0.7643 - auc: 0.9653 - loss: 0.0968 - val_accuracy: 0.7868 - val_auc: 0.9703 - val_loss: 0.0839 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7750 - auc: 0.9694 - loss: 0.0917\n",
      "Epoch 9: val_auc improved from 0.97034 to 0.97236, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.7750 - auc: 0.9694 - loss: 0.0917 - val_accuracy: 0.7893 - val_auc: 0.9724 - val_loss: 0.0792 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7965 - auc: 0.9739 - loss: 0.0792\n",
      "Epoch 10: val_auc improved from 0.97236 to 0.97394, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.7965 - auc: 0.9739 - loss: 0.0792 - val_accuracy: 0.7983 - val_auc: 0.9739 - val_loss: 0.0751 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8103 - auc: 0.9786 - loss: 0.0687\n",
      "Epoch 11: val_auc improved from 0.97394 to 0.97581, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.8103 - auc: 0.9786 - loss: 0.0687 - val_accuracy: 0.8093 - val_auc: 0.9758 - val_loss: 0.0732 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8225 - auc: 0.9791 - loss: 0.0685\n",
      "Epoch 12: val_auc improved from 0.97581 to 0.97617, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.8225 - auc: 0.9791 - loss: 0.0685 - val_accuracy: 0.8118 - val_auc: 0.9762 - val_loss: 0.0713 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8352 - auc: 0.9831 - loss: 0.0598\n",
      "Epoch 13: val_auc improved from 0.97617 to 0.97723, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.8352 - auc: 0.9831 - loss: 0.0598 - val_accuracy: 0.8198 - val_auc: 0.9772 - val_loss: 0.0693 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8381 - auc: 0.9827 - loss: 0.0594\n",
      "Epoch 14: val_auc improved from 0.97723 to 0.97735, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.8381 - auc: 0.9827 - loss: 0.0594 - val_accuracy: 0.8352 - val_auc: 0.9773 - val_loss: 0.0713 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8509 - auc: 0.9857 - loss: 0.0527\n",
      "Epoch 15: val_auc improved from 0.97735 to 0.97741, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8509 - auc: 0.9857 - loss: 0.0527 - val_accuracy: 0.8203 - val_auc: 0.9774 - val_loss: 0.0699 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8589 - auc: 0.9876 - loss: 0.0485\n",
      "Epoch 16: val_auc improved from 0.97741 to 0.97760, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.8589 - auc: 0.9876 - loss: 0.0485 - val_accuracy: 0.8328 - val_auc: 0.9776 - val_loss: 0.0713 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8663 - auc: 0.9884 - loss: 0.0493\n",
      "Epoch 17: val_auc improved from 0.97760 to 0.97897, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8663 - auc: 0.9884 - loss: 0.0493 - val_accuracy: 0.8337 - val_auc: 0.9790 - val_loss: 0.0684 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8802 - auc: 0.9904 - loss: 0.0388\n",
      "Epoch 18: val_auc did not improve from 0.97897\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.8801 - auc: 0.9904 - loss: 0.0388 - val_accuracy: 0.8258 - val_auc: 0.9783 - val_loss: 0.0734 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8836 - auc: 0.9919 - loss: 0.0364\n",
      "Epoch 19: val_auc did not improve from 0.97897\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.8837 - auc: 0.9919 - loss: 0.0364 - val_accuracy: 0.8258 - val_auc: 0.9780 - val_loss: 0.0706 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9931 - loss: 0.0314\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 20: val_auc did not improve from 0.97897\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9931 - loss: 0.0314 - val_accuracy: 0.8253 - val_auc: 0.9784 - val_loss: 0.0729 - learning_rate: 1.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8999 - auc: 0.9933 - loss: 0.0307\n",
      "Epoch 21: val_auc improved from 0.97897 to 0.97950, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.8999 - auc: 0.9933 - loss: 0.0307 - val_accuracy: 0.8313 - val_auc: 0.9795 - val_loss: 0.0717 - learning_rate: 1.0000e-06\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8979 - auc: 0.9939 - loss: 0.0296\n",
      "Epoch 22: val_auc improved from 0.97950 to 0.97997, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.8979 - auc: 0.9939 - loss: 0.0296 - val_accuracy: 0.8357 - val_auc: 0.9800 - val_loss: 0.0716 - learning_rate: 1.0000e-06\n",
      "Epoch 23/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9107 - auc: 0.9948 - loss: 0.0271\n",
      "Epoch 23: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 1s/step - accuracy: 0.9106 - auc: 0.9948 - loss: 0.0271 - val_accuracy: 0.8342 - val_auc: 0.9793 - val_loss: 0.0727 - learning_rate: 1.0000e-06\n",
      "Epoch 24/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9112 - auc: 0.9947 - loss: 0.0273\n",
      "Epoch 24: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.9112 - auc: 0.9947 - loss: 0.0273 - val_accuracy: 0.8352 - val_auc: 0.9795 - val_loss: 0.0722 - learning_rate: 1.0000e-06\n",
      "Epoch 25/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9114 - auc: 0.9944 - loss: 0.0274\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 25: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 1s/step - accuracy: 0.9114 - auc: 0.9944 - loss: 0.0275 - val_accuracy: 0.8382 - val_auc: 0.9795 - val_loss: 0.0722 - learning_rate: 1.0000e-06\n",
      "Epoch 26/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9095 - auc: 0.9952 - loss: 0.0243\n",
      "Epoch 26: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9095 - auc: 0.9952 - loss: 0.0243 - val_accuracy: 0.8367 - val_auc: 0.9795 - val_loss: 0.0729 - learning_rate: 1.0000e-07\n",
      "Epoch 27/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9128 - auc: 0.9948 - loss: 0.0255\n",
      "Epoch 27: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.9128 - auc: 0.9948 - loss: 0.0255 - val_accuracy: 0.8382 - val_auc: 0.9799 - val_loss: 0.0721 - learning_rate: 1.0000e-07\n",
      "Epoch 28/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9083 - auc: 0.9948 - loss: 0.0274\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 28: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.9083 - auc: 0.9948 - loss: 0.0274 - val_accuracy: 0.8397 - val_auc: 0.9796 - val_loss: 0.0720 - learning_rate: 1.0000e-07\n",
      "Epoch 29/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9088 - auc: 0.9943 - loss: 0.0280\n",
      "Epoch 29: val_auc did not improve from 0.97997\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9088 - auc: 0.9943 - loss: 0.0280 - val_accuracy: 0.8362 - val_auc: 0.9795 - val_loss: 0.0726 - learning_rate: 1.0000e-08\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "FOLD 4 - Loss: 0.0716, Accuracy: 0.8357, AUC: 0.9800\n",
      "\n",
      "\n",
      "===== FOLD 5/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       880\n",
      "bcc       411\n",
      "akiec     261\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       219\n",
      "bcc       103\n",
      "akiec      66\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6315 - auc: 0.8537 - loss: 0.2011\n",
      "Epoch 1: val_auc improved from -inf to 0.87734, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 292ms/step - accuracy: 0.6317 - auc: 0.8537 - loss: 0.2011 - val_accuracy: 0.6695 - val_auc: 0.8773 - val_loss: 0.1723\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6705 - auc: 0.8717 - loss: 0.1937\n",
      "Epoch 2: val_auc improved from 0.87734 to 0.89062, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 270ms/step - accuracy: 0.6705 - auc: 0.8717 - loss: 0.1937 - val_accuracy: 0.6695 - val_auc: 0.8906 - val_loss: 0.1713\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6678 - auc: 0.8743 - loss: 0.1868\n",
      "Epoch 3: val_auc did not improve from 0.89062\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 270ms/step - accuracy: 0.6678 - auc: 0.8743 - loss: 0.1868 - val_accuracy: 0.6695 - val_auc: 0.8878 - val_loss: 0.1714\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6617 - auc: 0.8749 - loss: 0.1879\n",
      "Epoch 4: val_auc improved from 0.89062 to 0.89399, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 273ms/step - accuracy: 0.6618 - auc: 0.8749 - loss: 0.1879 - val_accuracy: 0.6695 - val_auc: 0.8940 - val_loss: 0.1705\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6784 - auc: 0.8784 - loss: 0.1825\n",
      "Epoch 5: val_auc improved from 0.89399 to 0.89762, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 276ms/step - accuracy: 0.6784 - auc: 0.8784 - loss: 0.1825 - val_accuracy: 0.6695 - val_auc: 0.8976 - val_loss: 0.1695\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6705 - auc: 0.8804 - loss: 0.1780\n",
      "Epoch 6: val_auc did not improve from 0.89762\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.6705 - auc: 0.8803 - loss: 0.1780 - val_accuracy: 0.6695 - val_auc: 0.8908 - val_loss: 0.1707\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6604 - auc: 0.8783 - loss: 0.1862\n",
      "Epoch 7: val_auc did not improve from 0.89762\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.6605 - auc: 0.8783 - loss: 0.1862 - val_accuracy: 0.6690 - val_auc: 0.8924 - val_loss: 0.1695\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6713 - auc: 0.8809 - loss: 0.1815\n",
      "Epoch 8: val_auc did not improve from 0.89762\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.6713 - auc: 0.8809 - loss: 0.1815 - val_accuracy: 0.6685 - val_auc: 0.8942 - val_loss: 0.1688\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6199 - auc: 0.8747 - loss: 0.3355\n",
      "Epoch 1: val_auc improved from -inf to 0.80931, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - accuracy: 0.6199 - auc: 0.8748 - loss: 0.3353 - val_accuracy: 0.6695 - val_auc: 0.8093 - val_loss: 1.0561 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6564 - auc: 0.9217 - loss: 0.1815\n",
      "Epoch 2: val_auc improved from 0.80931 to 0.81006, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.6564 - auc: 0.9218 - loss: 0.1815 - val_accuracy: 0.6670 - val_auc: 0.8101 - val_loss: 1.1386 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6908 - auc: 0.9399 - loss: 0.1444\n",
      "Epoch 3: val_auc improved from 0.81006 to 0.87870, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.6909 - auc: 0.9399 - loss: 0.1444 - val_accuracy: 0.6705 - val_auc: 0.8787 - val_loss: 0.4371 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7335 - auc: 0.9559 - loss: 0.1155\n",
      "Epoch 4: val_auc improved from 0.87870 to 0.92761, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.7335 - auc: 0.9559 - loss: 0.1155 - val_accuracy: 0.6925 - val_auc: 0.9276 - val_loss: 0.1947 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7523 - auc: 0.9623 - loss: 0.1033\n",
      "Epoch 5: val_auc improved from 0.92761 to 0.97152, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.7523 - auc: 0.9623 - loss: 0.1032 - val_accuracy: 0.7968 - val_auc: 0.9715 - val_loss: 0.0835 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7675 - auc: 0.9670 - loss: 0.0949\n",
      "Epoch 6: val_auc improved from 0.97152 to 0.97789, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.7675 - auc: 0.9670 - loss: 0.0949 - val_accuracy: 0.8158 - val_auc: 0.9779 - val_loss: 0.0697 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7867 - auc: 0.9739 - loss: 0.0816\n",
      "Epoch 7: val_auc improved from 0.97789 to 0.97858, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.7867 - auc: 0.9739 - loss: 0.0816 - val_accuracy: 0.8103 - val_auc: 0.9786 - val_loss: 0.0669 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8061 - auc: 0.9765 - loss: 0.0760\n",
      "Epoch 8: val_auc improved from 0.97858 to 0.97953, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.8061 - auc: 0.9765 - loss: 0.0760 - val_accuracy: 0.8173 - val_auc: 0.9795 - val_loss: 0.0637 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8253 - auc: 0.9814 - loss: 0.0618\n",
      "Epoch 9: val_auc improved from 0.97953 to 0.98057, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.8253 - auc: 0.9814 - loss: 0.0618 - val_accuracy: 0.8228 - val_auc: 0.9806 - val_loss: 0.0623 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8276 - auc: 0.9818 - loss: 0.0626\n",
      "Epoch 10: val_auc improved from 0.98057 to 0.98174, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8277 - auc: 0.9819 - loss: 0.0626 - val_accuracy: 0.8308 - val_auc: 0.9817 - val_loss: 0.0597 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8371 - auc: 0.9841 - loss: 0.0547\n",
      "Epoch 11: val_auc improved from 0.98174 to 0.98238, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.8371 - auc: 0.9841 - loss: 0.0547 - val_accuracy: 0.8337 - val_auc: 0.9824 - val_loss: 0.0582 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8499 - auc: 0.9866 - loss: 0.0542\n",
      "Epoch 12: val_auc improved from 0.98238 to 0.98315, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.8499 - auc: 0.9866 - loss: 0.0542 - val_accuracy: 0.8318 - val_auc: 0.9831 - val_loss: 0.0579 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8674 - auc: 0.9892 - loss: 0.0428\n",
      "Epoch 13: val_auc improved from 0.98315 to 0.98329, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8674 - auc: 0.9892 - loss: 0.0428 - val_accuracy: 0.8352 - val_auc: 0.9833 - val_loss: 0.0579 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8744 - auc: 0.9897 - loss: 0.0402\n",
      "Epoch 14: val_auc did not improve from 0.98329\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.8744 - auc: 0.9897 - loss: 0.0402 - val_accuracy: 0.8372 - val_auc: 0.9832 - val_loss: 0.0579 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8877 - auc: 0.9917 - loss: 0.0368\n",
      "Epoch 15: val_auc did not improve from 0.98329\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8877 - auc: 0.9917 - loss: 0.0368 - val_accuracy: 0.8377 - val_auc: 0.9830 - val_loss: 0.0581 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8982 - auc: 0.9935 - loss: 0.0302\n",
      "Epoch 16: val_auc improved from 0.98329 to 0.98426, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8982 - auc: 0.9935 - loss: 0.0302 - val_accuracy: 0.8462 - val_auc: 0.9843 - val_loss: 0.0566 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8984 - auc: 0.9936 - loss: 0.0309\n",
      "Epoch 17: val_auc did not improve from 0.98426\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.8984 - auc: 0.9936 - loss: 0.0309 - val_accuracy: 0.8313 - val_auc: 0.9821 - val_loss: 0.0669 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9069 - auc: 0.9947 - loss: 0.0261\n",
      "Epoch 18: val_auc did not improve from 0.98426\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9069 - auc: 0.9947 - loss: 0.0261 - val_accuracy: 0.8422 - val_auc: 0.9832 - val_loss: 0.0621 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9166 - auc: 0.9952 - loss: 0.0261\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 19: val_auc improved from 0.98426 to 0.98429, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.9166 - auc: 0.9952 - loss: 0.0261 - val_accuracy: 0.8492 - val_auc: 0.9843 - val_loss: 0.0603 - learning_rate: 1.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9281 - auc: 0.9965 - loss: 0.0225\n",
      "Epoch 20: val_auc improved from 0.98429 to 0.98451, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 1s/step - accuracy: 0.9281 - auc: 0.9965 - loss: 0.0225 - val_accuracy: 0.8452 - val_auc: 0.9845 - val_loss: 0.0588 - learning_rate: 1.0000e-06\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9311 - auc: 0.9966 - loss: 0.0205\n",
      "Epoch 21: val_auc improved from 0.98451 to 0.98458, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.9311 - auc: 0.9966 - loss: 0.0205 - val_accuracy: 0.8457 - val_auc: 0.9846 - val_loss: 0.0593 - learning_rate: 1.0000e-06\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9260 - auc: 0.9966 - loss: 0.0203\n",
      "Epoch 22: val_auc did not improve from 0.98458\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 1s/step - accuracy: 0.9260 - auc: 0.9966 - loss: 0.0203 - val_accuracy: 0.8447 - val_auc: 0.9844 - val_loss: 0.0600 - learning_rate: 1.0000e-06\n",
      "Epoch 23/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9313 - auc: 0.9965 - loss: 0.0205\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 23: val_auc did not improve from 0.98458\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 1s/step - accuracy: 0.9314 - auc: 0.9965 - loss: 0.0205 - val_accuracy: 0.8427 - val_auc: 0.9835 - val_loss: 0.0616 - learning_rate: 1.0000e-06\n",
      "Epoch 24/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9279 - auc: 0.9967 - loss: 0.0198\n",
      "Epoch 24: val_auc did not improve from 0.98458\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9279 - auc: 0.9967 - loss: 0.0198 - val_accuracy: 0.8422 - val_auc: 0.9844 - val_loss: 0.0606 - learning_rate: 1.0000e-07\n",
      "Epoch 25/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9335 - auc: 0.9968 - loss: 0.0196\n",
      "Epoch 25: val_auc did not improve from 0.98458\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9335 - auc: 0.9968 - loss: 0.0196 - val_accuracy: 0.8437 - val_auc: 0.9842 - val_loss: 0.0607 - learning_rate: 1.0000e-07\n",
      "Epoch 26/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9362 - auc: 0.9973 - loss: 0.0169\n",
      "Epoch 26: val_auc improved from 0.98458 to 0.98464, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.9362 - auc: 0.9973 - loss: 0.0169 - val_accuracy: 0.8447 - val_auc: 0.9846 - val_loss: 0.0600 - learning_rate: 1.0000e-07\n",
      "Epoch 27/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9363 - auc: 0.9973 - loss: 0.0181\n",
      "Epoch 27: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9363 - auc: 0.9973 - loss: 0.0181 - val_accuracy: 0.8417 - val_auc: 0.9838 - val_loss: 0.0613 - learning_rate: 1.0000e-07\n",
      "Epoch 28/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9335 - auc: 0.9972 - loss: 0.0181\n",
      "Epoch 28: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9335 - auc: 0.9972 - loss: 0.0181 - val_accuracy: 0.8402 - val_auc: 0.9837 - val_loss: 0.0618 - learning_rate: 1.0000e-07\n",
      "Epoch 29/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9327 - auc: 0.9969 - loss: 0.0201\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 29: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9327 - auc: 0.9969 - loss: 0.0201 - val_accuracy: 0.8397 - val_auc: 0.9835 - val_loss: 0.0620 - learning_rate: 1.0000e-07\n",
      "Epoch 30/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9368 - auc: 0.9972 - loss: 0.0180\n",
      "Epoch 30: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 1s/step - accuracy: 0.9368 - auc: 0.9972 - loss: 0.0180 - val_accuracy: 0.8412 - val_auc: 0.9838 - val_loss: 0.0615 - learning_rate: 1.0000e-08\n",
      "Epoch 31/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9297 - auc: 0.9971 - loss: 0.0188\n",
      "Epoch 31: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9297 - auc: 0.9971 - loss: 0.0188 - val_accuracy: 0.8382 - val_auc: 0.9837 - val_loss: 0.0616 - learning_rate: 1.0000e-08\n",
      "Epoch 32/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9254 - auc: 0.9966 - loss: 0.0213\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "\n",
      "Epoch 32: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 1s/step - accuracy: 0.9255 - auc: 0.9966 - loss: 0.0213 - val_accuracy: 0.8422 - val_auc: 0.9839 - val_loss: 0.0610 - learning_rate: 1.0000e-08\n",
      "Epoch 33/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9355 - auc: 0.9972 - loss: 0.0186\n",
      "Epoch 33: val_auc did not improve from 0.98464\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 1s/step - accuracy: 0.9355 - auc: 0.9972 - loss: 0.0186 - val_accuracy: 0.8442 - val_auc: 0.9841 - val_loss: 0.0606 - learning_rate: 1.0000e-09\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "FOLD 5 - Loss: 0.0600, Accuracy: 0.8447, AUC: 0.9846\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "Average Loss over 5 folds  : 0.0674 (± 0.0041)\n",
      "Average Accuracy over 5 folds: 0.8429 (± 0.0075)\n",
      "Average AUC over 5 folds     : 0.9816 (± 0.0018)\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# For tracking the best fold, to later evaluate performance\n",
    "best_fold = None\n",
    "best_auc_across_folds = 0.0\n",
    "\n",
    "# For collecting metrics across folds\n",
    "fold_accuracies = []\n",
    "fold_aucs = []\n",
    "fold_losses = []\n",
    "\n",
    "# Epochs for each phase\n",
    "EPOCHS_PHASE1 = 20   # Freeze the backbone\n",
    "EPOCHS_PHASE2 = 200  # Fine-tuning\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "base_resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=None)\n",
    "\n",
    "# Data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen_val = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Get unique class labels (strings)\n",
    "all_class_labels = sorted(df['dx'].unique())\n",
    "\n",
    "# Compute global class weights for the entire dataset\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(all_class_labels),\n",
    "    y=df['dx'].values\n",
    ")\n",
    "# Map to dictionary: {class_index: weight}\n",
    "class_weights_dict = {}\n",
    "for label, w in zip(all_class_labels, class_weights_array):\n",
    "    # Index of this label in the alphabetical-sorted list\n",
    "    idx = all_class_labels.index(label)\n",
    "    class_weights_dict[idx] = w\n",
    "print(\"Class weights dict:\", class_weights_dict)\n",
    "\n",
    "fold_index = 1\n",
    "for train_idx, val_idx in skf.split(df, df['dx']):\n",
    "    print(f\"\\n\\n===== FOLD {fold_index}/{k_folds} =====\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.1) CREATE DATAFRAMES FOR THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "    print(\"Train distribution:\\n\", train_df['dx'].value_counts())\n",
    "    print(\"Val distribution:\\n\", val_df['dx'].value_counts())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.2) FLOW FROM DATAFRAME: TRAIN & VAL\n",
    "    # ------------------------------------------------------\n",
    "    train_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_generator = datagen_val.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Extract class names from the train_generator\n",
    "    # The generator creates an internal mapping of classes -> indices\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.3) BUILD & COMPILE MODEL FROM SCRATCH FOR EACH FOLD\n",
    "    # ------------------------------------------------------\n",
    "    custom_resnet = build_resnet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "    # Transfer weights from base Keras ResNet50 (ImageNet) to custom ResNet\n",
    "    transfer_weights(base_resnet50, custom_resnet)\n",
    "\n",
    "    # Freeze layers in the main body\n",
    "    for layer in custom_resnet.layers:\n",
    "        if layer.name.startswith('conv'):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.4) CALLBACKS & TRAIN (PHASE 1)\n",
    "    # ------------------------------------------------------\n",
    "    model_path_phase1 = f\"resnet50_cbam_classificationhead_fold{fold_index}_phase1.keras\"\n",
    "    callbacks_phase1 = [\n",
    "        EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase1, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase1 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE1,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase1\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 1\n",
    "    custom_resnet.load_weights(model_path_phase1)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.5) UNFREEZE & FINE-TUNING (PHASE 2)\n",
    "    # ------------------------------------------------------\n",
    "    for layer in custom_resnet.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    model_path_phase2 = f\"resnet50_cbam_classificationhead_fold{fold_index}_phase2.keras\"\n",
    "    callbacks_phase2 = [\n",
    "        ReduceLROnPlateau(monitor='val_auc', factor=0.1, patience=3, mode='max', verbose=1),\n",
    "        EarlyStopping(monitor='val_auc', patience=7, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase2, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase2 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE2,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase2\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 2\n",
    "    custom_resnet.load_weights(model_path_phase2)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.6) EVALUATE ON THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    loss, accuracy, auc_val = custom_resnet.evaluate(val_generator, verbose=0)\n",
    "    print(f\"FOLD {fold_index} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc_val:.4f}\")\n",
    "\n",
    "    fold_losses.append(loss)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_aucs.append(auc_val)\n",
    "\n",
    "    # Check if this fold is the best so far\n",
    "    if auc_val > best_auc_across_folds:\n",
    "        best_auc_across_folds = auc_val\n",
    "        best_fold = fold_index\n",
    "\n",
    "    # Move to next fold\n",
    "    fold_index += 1\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5) CROSS-VALIDATION RESULTS\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"\\n=== CROSS-VALIDATION RESULTS ===\")\n",
    "print(f\"Average Loss over {k_folds} folds  : {np.mean(fold_losses):.4f} (± {np.std(fold_losses):.4f})\")\n",
    "print(f\"Average Accuracy over {k_folds} folds: {np.mean(fold_accuracies):.4f} (± {np.std(fold_accuracies):.4f})\")\n",
    "print(f\"Average AUC over {k_folds} folds     : {np.mean(fold_aucs):.4f} (± {np.std(fold_aucs):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = f\"resnet50_fold{best_fold}_phase2.keras\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 6) EVALUATE BEST MODEL ON TEST SET\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Load best model\n",
    "best_model = tf.keras.models.load_model(best_model_path, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(best_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtest_generator\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "# Get predictions\n",
    "y_pred = np.argmax(best_model.predict(test_generator), axis=-1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
