{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Layer, Reshape, Multiply, Conv2D, BatchNormalization, Activation, Add, Input, ZeroPadding2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                          image_path  \n",
      "0  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "1  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "2  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "3  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "4  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "Total samples in dataset: 10015\n"
     ]
    }
   ],
   "source": [
    "base = '/Users/robp/scm/personal/github.com/robpickerill/thesis'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Total samples in dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable(package=\"Custom\")\n",
    "class CBAM(Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Block Attention Module (CBAM)\n",
    "\n",
    "    Reference: \"CBAM: Convolutional Block Attention Module\"\n",
    "    (Woo et al., ECCV 2018) - https://arxiv.org/abs/1807.06521\n",
    "\n",
    "    The CBAM block applies both Channel Attention and Spatial Attention\n",
    "    to refine feature maps adaptively. It consists of two sequential sub-blocks:\n",
    "\n",
    "    1. Channel Attention Module (CAM):\n",
    "       - Uses both global average and max pooling operations to generate channel descriptors.\n",
    "       - Passes them through a shared MLP to produce channel-wise weights.\n",
    "       - The output is a channel attention map that emphasizes meaningful channels.\n",
    "\n",
    "    2. Spatial Attention Module (SAM):\n",
    "       - Uses average and max pooling along the channel dimension to produce spatial descriptors.\n",
    "       - Applies a convolution (often 7x7) to produce a spatial attention map.\n",
    "       - This map emphasizes \"where\" to focus within each channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reduction_ratio : int, optional (default=16)\n",
    "        Reduction ratio for the internal MLP in the channel attention module.\n",
    "\n",
    "    spatial_kernel_size : int, optional (default=7)\n",
    "        The kernel size for the spatial attention convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, spatial_kernel_size=7, name=None, **kwargs):\n",
    "        super(CBAM, self).__init__(name=name, **kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        self.spatial_kernel_size = spatial_kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"CBAM input must be in the shape: (batch, height, width, channels)\")\n",
    "\n",
    "        channels = input_shape[-1]\n",
    "        reduced_channels = max(channels // self.reduction_ratio, 1)\n",
    "\n",
    "        # Shared MLP for channel attention\n",
    "        # Two Dense layers: C -> C//r -> C\n",
    "        self.mlp_dense_1 = Dense(units=reduced_channels,\n",
    "                                        activation='relu',\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_1')\n",
    "        self.mlp_dense_2 = Dense(units=channels,\n",
    "                                        use_bias=True,\n",
    "                                        name='channel_mlp_2')\n",
    "\n",
    "        # No weights needed to pre-build for the spatial attention layer\n",
    "        # since we'll use a Conv2D layer directly on the fly.\n",
    "        self.spatial_conv = Conv2D(filters=1,\n",
    "                                          kernel_size=self.spatial_kernel_size,\n",
    "                                          strides=1,\n",
    "                                          padding='same',\n",
    "                                          activation='sigmoid',\n",
    "                                          use_bias=False,\n",
    "                                          name='spatial_conv')\n",
    "\n",
    "        super(CBAM, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # ----- Channel Attention -----\n",
    "        # Global average pooling\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)  # (batch, C)\n",
    "        # Global max pooling\n",
    "        max_pool = tf.reduce_max(inputs, axis=[1, 2], keepdims=False)   # (batch, C)\n",
    "\n",
    "        # Shared MLP transforms\n",
    "        avg_out = self.mlp_dense_2(self.mlp_dense_1(avg_pool, training=training), training=training)\n",
    "        max_out = self.mlp_dense_2(self.mlp_dense_1(max_pool, training=training), training=training)\n",
    "\n",
    "        # Combine and apply sigmoid\n",
    "        channel_attention = tf.nn.sigmoid(avg_out + max_out)  # (batch, C)\n",
    "\n",
    "        # Reshape to broadcast\n",
    "        channel_attention = tf.reshape(channel_attention, [-1, 1, 1, tf.shape(inputs)[-1]])\n",
    "        channel_refined = inputs * channel_attention\n",
    "\n",
    "        # ----- Spatial Attention -----\n",
    "        # Avg and max along channel axis\n",
    "        avg_spatial = tf.reduce_mean(channel_refined, axis=-1, keepdims=True)  # (batch, H, W, 1)\n",
    "        max_spatial = tf.reduce_max(channel_refined, axis=-1, keepdims=True)   # (batch, H, W, 1)\n",
    "\n",
    "        # Concatenate along channel axis\n",
    "        spatial_concat = tf.concat([avg_spatial, max_spatial], axis=-1)  # (batch, H, W, 2)\n",
    "\n",
    "        # Apply spatial conv\n",
    "        spatial_attention = self.spatial_conv(spatial_concat, training=training)  # (batch, H, W, 1)\n",
    "\n",
    "        # Refine features spatially\n",
    "        refined_outputs = channel_refined * spatial_attention\n",
    "        return refined_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CBAM, self).get_config()\n",
    "        config.update({\n",
    "            'reduction_ratio': self.reduction_ratio,\n",
    "            'spatial_kernel_size': self.spatial_kernel_size\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    x = CBAM()(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, input_tensor])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '0_conv')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '0_bn')(shortcut)\n",
    "\n",
    "    x = CBAM()(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, shortcut])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape, name='input_1')\n",
    "    bn_axis = 3  # channels_last\n",
    "\n",
    "    # Stage 1\n",
    "    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "               padding='valid', use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name='conv1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1_pool')(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    # Stage 3\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    # Stage 4\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    # Stage 5\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    # Global Pooling & Classifier\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name='resnet50')\n",
    "    return model\n",
    "\n",
    "def transfer_weights(base_model, target_model):\n",
    "    \"\"\"\n",
    "    Transfer weights from a Keras ResNet50 base_model into the custom ResNet50\n",
    "    architecture whenever layer names match.\n",
    "    \"\"\"\n",
    "    for layer in target_model.layers:\n",
    "        try:\n",
    "            pretrained_layer = base_model.get_layer(layer.name)\n",
    "            layer.set_weights(pretrained_layer.get_weights())\n",
    "        except Exception:\n",
    "            # If layer doesn't exist in pretrained base, skip\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weights = alpha * y_true * tf.math.pow((1 - y_pred), gamma)\n",
    "        return tf.reduce_mean(tf.reduce_sum(weights * cross_entropy, axis=-1))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights dict: {0: 4.375273044997815, 1: 2.78349082823791, 2: 1.301832835044846, 3: 12.440993788819876, 4: 1.2854575792581184, 5: 0.21338020666879728, 6: 10.075452716297788}\n",
      "\n",
      "\n",
      "===== FOLD 1/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.6105 - auc: 0.8382 - loss: 0.2267\n",
      "Epoch 1: val_auc improved from -inf to 0.87772, saving model to resnet50_cbam_stage2345_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 857ms/step - accuracy: 0.6107 - auc: 0.8383 - loss: 0.2266 - val_accuracy: 0.6695 - val_auc: 0.8777 - val_loss: 0.1755\n",
      "Epoch 2/20\n",
      "\u001b[1m 57/251\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 799ms/step - accuracy: 0.6724 - auc: 0.8762 - loss: 0.1869"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 123\u001b[0m\n\u001b[1;32m    117\u001b[0m model_path_phase1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50_cbam_stage2345_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_phase1.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m callbacks_phase1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    119\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    120\u001b[0m     ModelCheckpoint(model_path_phase1, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    121\u001b[0m ]\n\u001b[0;32m--> 123\u001b[0m history_phase1 \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_resnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS_PHASE1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_phase1\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Load best weights from Phase 1\u001b[39;00m\n\u001b[1;32m    132\u001b[0m custom_resnet\u001b[38;5;241m.\u001b[39mload_weights(model_path_phase1)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/scm/personal/github.com/robpickerill/thesis/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# For tracking the best fold, to later evaluate performance\n",
    "best_fold = None\n",
    "best_auc_across_folds = 0.0\n",
    "\n",
    "# For collecting metrics across folds\n",
    "fold_accuracies = []\n",
    "fold_aucs = []\n",
    "fold_losses = []\n",
    "\n",
    "# Epochs for each phase\n",
    "EPOCHS_PHASE1 = 20   # Freeze the backbone\n",
    "EPOCHS_PHASE2 = 200  # Fine-tuning\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "base_resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=None)\n",
    "\n",
    "# Data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen_val = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Get unique class labels (strings)\n",
    "all_class_labels = sorted(df['dx'].unique())\n",
    "\n",
    "# Compute global class weights for the entire dataset\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(all_class_labels),\n",
    "    y=df['dx'].values\n",
    ")\n",
    "# Map to dictionary: {class_index: weight}\n",
    "class_weights_dict = {}\n",
    "for label, w in zip(all_class_labels, class_weights_array):\n",
    "    # Index of this label in the alphabetical-sorted list\n",
    "    idx = all_class_labels.index(label)\n",
    "    class_weights_dict[idx] = w\n",
    "print(\"Class weights dict:\", class_weights_dict)\n",
    "\n",
    "fold_index = 1\n",
    "for train_idx, val_idx in skf.split(df, df['dx']):\n",
    "    print(f\"\\n\\n===== FOLD {fold_index}/{k_folds} =====\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.1) CREATE DATAFRAMES FOR THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "    print(\"Train distribution:\\n\", train_df['dx'].value_counts())\n",
    "    print(\"Val distribution:\\n\", val_df['dx'].value_counts())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.2) FLOW FROM DATAFRAME: TRAIN & VAL\n",
    "    # ------------------------------------------------------\n",
    "    train_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_generator = datagen_val.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Extract class names from the train_generator\n",
    "    # The generator creates an internal mapping of classes -> indices\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.3) BUILD & COMPILE MODEL FROM SCRATCH FOR EACH FOLD\n",
    "    # ------------------------------------------------------\n",
    "    custom_resnet = build_resnet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "    # Transfer weights from base Keras ResNet50 (ImageNet) to custom ResNet\n",
    "    transfer_weights(base_resnet50, custom_resnet)\n",
    "\n",
    "    # Freeze layers in the main body\n",
    "    for layer in custom_resnet.layers:\n",
    "        if layer.name.startswith('conv'):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.4) CALLBACKS & TRAIN (PHASE 1)\n",
    "    # ------------------------------------------------------\n",
    "    model_path_phase1 = f\"resnet50_cbam_stage2345_fold{fold_index}_phase1.keras\"\n",
    "    callbacks_phase1 = [\n",
    "        EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase1, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase1 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE1,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase1\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 1\n",
    "    custom_resnet.load_weights(model_path_phase1)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.5) UNFREEZE & FINE-TUNING (PHASE 2)\n",
    "    # ------------------------------------------------------\n",
    "    for layer in custom_resnet.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    model_path_phase2 = f\"resnet50_cbam_stage2345_fold{fold_index}_phase2.keras\"\n",
    "    callbacks_phase2 = [\n",
    "        ReduceLROnPlateau(monitor='val_auc', factor=0.1, patience=3, mode='max', verbose=1),\n",
    "        EarlyStopping(monitor='val_auc', patience=7, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase2, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase2 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE2,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase2\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 2\n",
    "    custom_resnet.load_weights(model_path_phase2)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.6) EVALUATE ON THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    loss, accuracy, auc_val = custom_resnet.evaluate(val_generator, verbose=0)\n",
    "    print(f\"FOLD {fold_index} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc_val:.4f}\")\n",
    "\n",
    "    fold_losses.append(loss)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_aucs.append(auc_val)\n",
    "\n",
    "    # Check if this fold is the best so far\n",
    "    if auc_val > best_auc_across_folds:\n",
    "        best_auc_across_folds = auc_val\n",
    "        best_fold = fold_index\n",
    "\n",
    "    # Move to next fold\n",
    "    fold_index += 1\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5) CROSS-VALIDATION RESULTS\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"\\n=== CROSS-VALIDATION RESULTS ===\")\n",
    "print(f\"Average Loss over {k_folds} folds  : {np.mean(fold_losses):.4f} (± {np.std(fold_losses):.4f})\")\n",
    "print(f\"Average Accuracy over {k_folds} folds: {np.mean(fold_accuracies):.4f} (± {np.std(fold_accuracies):.4f})\")\n",
    "print(f\"Average AUC over {k_folds} folds     : {np.mean(fold_aucs):.4f} (± {np.std(fold_aucs):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = f\"resnet50_fold{best_fold}_phase2.keras\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 6) EVALUATE BEST MODEL ON TEST SET\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Load best model\n",
    "best_model = tf.keras.models.load_model(best_model_path, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(best_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtest_generator\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "# Get predictions\n",
    "y_pred = np.argmax(best_model.predict(test_generator), axis=-1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
