{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Layer, Reshape, Multiply, Conv2D, BatchNormalization, Activation, Add, Input, ZeroPadding2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                          image_path  \n",
      "0  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "1  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "2  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "3  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "4  /Users/robp/scm/personal/github.com/robpickeri...  \n",
      "Total samples in dataset: 10015\n"
     ]
    }
   ],
   "source": [
    "base = '/Users/robp/scm/personal/github.com/robpickerill/thesis'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Total samples in dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class SEBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation (SE) Block\n",
    "\n",
    "    The SE block recalibrates channel-wise feature responses by explicitly modeling\n",
    "    interdependencies between channels. Given an input feature map of shape\n",
    "    (batch, height, width, channels), it:\n",
    "\n",
    "    1. Squeezes global spatial information into a channel descriptor by using\n",
    "       global average pooling.\n",
    "    2. Excites each channel by passing this descriptor through a fully-connected\n",
    "       bottleneck and expanding transformation, utilizing a sigmoid activation\n",
    "       to generate channel-wise weights.\n",
    "    3. Scales the original feature map by these learned weights,\n",
    "       reinforcing channels that are relevant and suppressing those that are not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reduction_ratio : int, optional (default=16)\n",
    "        The reduction ratio used to compute the size of the bottleneck layer.\n",
    "        For an input with `C` channels, the bottleneck layer will have\n",
    "        `C // reduction_ratio` channels.\n",
    "\n",
    "    name : str, optional\n",
    "        String name for the layer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    fc1 : Dense layer\n",
    "        The first fully connected layer that reduces the channel dimension.\n",
    "    fc2 : Dense layer\n",
    "        The second fully connected layer that expands back to the original channel dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, name=None, **kwargs):\n",
    "        super(SEBlock, self).__init__(name=name, **kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Build the internal layers of the SE block. This method is called\n",
    "        automatically once the shape of the inputs is known.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : TensorShape\n",
    "            The shape of the input tensor. Typically (batch, height, width, channels).\n",
    "        \"\"\"\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"SEBlock only supports inputs with shape (batch, height, width, channels).\")\n",
    "\n",
    "        channels = input_shape[-1]\n",
    "        reduced_channels = max(channels // self.reduction_ratio, 1)\n",
    "\n",
    "        # First FC layer for reduction (C -> C//r)\n",
    "        self.fc1 = layers.Dense(units=reduced_channels,\n",
    "                                activation='relu',  # Non-linear activation\n",
    "                                use_bias=True,\n",
    "                                name='se_fc1')\n",
    "\n",
    "        # Second FC layer to restore original dimension (C//r -> C)\n",
    "        self.fc2 = layers.Dense(units=channels,\n",
    "                                activation='sigmoid',  # Outputs channel-wise gating weights\n",
    "                                use_bias=True,\n",
    "                                name='se_fc2')\n",
    "\n",
    "        super(SEBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass of the SE block.\n",
    "\n",
    "        Steps:\n",
    "        1. Global average pooling to get channel-wise statistics of shape (batch, channels).\n",
    "        2. Pass through the first FC layer (reduction).\n",
    "        3. Pass through the second FC layer (expansion) with sigmoid activation to get weights.\n",
    "        4. Reshape weights to (batch, 1, 1, channels) to match the input shape.\n",
    "        5. Multiply the original inputs by these weights (channel-wise scaling).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : tf.Tensor\n",
    "            The input tensor with shape (batch, height, width, channels).\n",
    "\n",
    "        training : bool, optional\n",
    "            Specifies if the layer should behave in training mode or inference mode.\n",
    "            This parameter can be used by certain layers that behave differently\n",
    "            during training and inference.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tf.Tensor\n",
    "            The output tensor with the same shape as `inputs`, after channel-wise rescaling.\n",
    "        \"\"\"\n",
    "        # Step 1: Squeeze\n",
    "        # Global average pooling: (batch, H, W, C) -> (batch, C)\n",
    "        squeeze_tensor = tf.reduce_mean(inputs, axis=[1, 2], keepdims=False)\n",
    "\n",
    "        # Step 2 & 3: Excitation\n",
    "        # FC reduce: (batch, C) -> (batch, C//r)\n",
    "        reduced = self.fc1(squeeze_tensor, training=training)\n",
    "        # FC expand: (batch, C//r) -> (batch, C)\n",
    "        excitation = self.fc2(reduced, training=training)\n",
    "\n",
    "        # Reshape excitation to (batch, 1, 1, C) for broadcasting\n",
    "        excitation = tf.reshape(excitation, [-1, 1, 1, tf.shape(inputs)[-1]])\n",
    "\n",
    "        # Step 4: Scale\n",
    "        # Scale input by the learned weights: (batch, H, W, C)\n",
    "        scaled_inputs = inputs * excitation\n",
    "        return scaled_inputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "        Compute the output shape of the SE block. It remains the same as the input shape.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_shape : Tuple[int]\n",
    "            Shape of the input tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[int]\n",
    "            The output shape, identical to the input shape.\n",
    "        \"\"\"\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the layer. This enables the layer\n",
    "        to be serialized and deserialized, for example, when saving and loading models.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing the layer configuration.\n",
    "        \"\"\"\n",
    "        config = super(SEBlock, self).get_config()\n",
    "        config.update({\n",
    "            'reduction_ratio': self.reduction_ratio\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    if stage == 5:\n",
    "        x = SEBlock()(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, input_tensor])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    bn_axis = 3\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = f'conv{stage}_block{block}_'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '1_conv')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '1_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '1_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '2_bn')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '3_bn')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      use_bias=True,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '0_conv')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=conv_name_base + '0_bn')(shortcut)\n",
    "\n",
    "    if stage == 5:\n",
    "        x = SEBlock()(x)\n",
    "\n",
    "    x = Add(name=conv_name_base + 'add')([x, shortcut])\n",
    "    x = Activation('relu', name=conv_name_base + 'out')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet50(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape, name='input_1')\n",
    "    bn_axis = 3  # channels_last\n",
    "\n",
    "    # Stage 1\n",
    "    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "               padding='valid', use_bias=True,\n",
    "               kernel_initializer='he_normal',\n",
    "               name='conv1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1_pool')(x)\n",
    "\n",
    "    # Stage 2\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block=1, strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=2)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block=3)\n",
    "\n",
    "    # Stage 3\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block=1)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=2)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=3)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=4)\n",
    "\n",
    "    # Stage 4\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block=1)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=3)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=4)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=5)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=6)\n",
    "\n",
    "    # Stage 5\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block=1)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block=3)\n",
    "\n",
    "    # Global Pooling & Classifier\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name='resnet50')\n",
    "    return model\n",
    "\n",
    "def transfer_weights(base_model, target_model):\n",
    "    \"\"\"\n",
    "    Transfer weights from a Keras ResNet50 base_model into the custom ResNet50\n",
    "    architecture whenever layer names match.\n",
    "    \"\"\"\n",
    "    for layer in target_model.layers:\n",
    "        try:\n",
    "            pretrained_layer = base_model.get_layer(layer.name)\n",
    "            layer.set_weights(pretrained_layer.get_weights())\n",
    "        except Exception:\n",
    "            # If layer doesn't exist in pretrained base, skip\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weights = alpha * y_true * tf.math.pow((1 - y_pred), gamma)\n",
    "        return tf.reduce_mean(tf.reduce_sum(weights * cross_entropy, axis=-1))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights dict: {0: np.float64(4.375273044997815), 1: np.float64(2.78349082823791), 2: np.float64(1.301832835044846), 3: np.float64(12.440993788819876), 4: np.float64(1.2854575792581184), 5: np.float64(0.21338020666879728), 6: np.float64(10.075452716297788)}\n",
      "\n",
      "\n",
      "===== FOLD 1/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/.local/share/virtualenvs/account-management-Kww3qb6U/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.6144 - auc: 0.8494 - loss: 0.2249\n",
      "Epoch 1: val_auc improved from -inf to 0.88608, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.6146 - auc: 0.8495 - loss: 0.2248 - val_accuracy: 0.6695 - val_auc: 0.8861 - val_loss: 0.1712\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857ms/step - accuracy: 0.6686 - auc: 0.8733 - loss: 0.1869\n",
      "Epoch 2: val_auc did not improve from 0.88608\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 1s/step - accuracy: 0.6686 - auc: 0.8733 - loss: 0.1869 - val_accuracy: 0.6695 - val_auc: 0.8829 - val_loss: 0.1766\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824ms/step - accuracy: 0.6726 - auc: 0.8753 - loss: 0.1811\n",
      "Epoch 3: val_auc improved from 0.88608 to 0.89203, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.6726 - auc: 0.8753 - loss: 0.1811 - val_accuracy: 0.6695 - val_auc: 0.8920 - val_loss: 0.1705\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.6661 - auc: 0.8710 - loss: 0.1992\n",
      "Epoch 4: val_auc did not improve from 0.89203\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 1s/step - accuracy: 0.6661 - auc: 0.8710 - loss: 0.1992 - val_accuracy: 0.6695 - val_auc: 0.8917 - val_loss: 0.1724\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - accuracy: 0.6706 - auc: 0.8776 - loss: 0.1847\n",
      "Epoch 5: val_auc improved from 0.89203 to 0.89634, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 1s/step - accuracy: 0.6706 - auc: 0.8776 - loss: 0.1847 - val_accuracy: 0.6695 - val_auc: 0.8963 - val_loss: 0.1707\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831ms/step - accuracy: 0.6678 - auc: 0.8756 - loss: 0.1891\n",
      "Epoch 6: val_auc improved from 0.89634 to 0.89740, saving model to resnet50_cbam_classificationhead_fold1_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.6678 - auc: 0.8756 - loss: 0.1891 - val_accuracy: 0.6695 - val_auc: 0.8974 - val_loss: 0.1694\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.6819 - auc: 0.8840 - loss: 0.1705\n",
      "Epoch 7: val_auc did not improve from 0.89740\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 1s/step - accuracy: 0.6818 - auc: 0.8840 - loss: 0.1705 - val_accuracy: 0.6695 - val_auc: 0.8948 - val_loss: 0.1718\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - accuracy: 0.6623 - auc: 0.8773 - loss: 0.1915\n",
      "Epoch 8: val_auc did not improve from 0.89740\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 1s/step - accuracy: 0.6623 - auc: 0.8773 - loss: 0.1915 - val_accuracy: 0.6695 - val_auc: 0.8948 - val_loss: 0.1694\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - accuracy: 0.6678 - auc: 0.8761 - loss: 0.1953\n",
      "Epoch 9: val_auc did not improve from 0.89740\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 1s/step - accuracy: 0.6678 - auc: 0.8761 - loss: 0.1953 - val_accuracy: 0.6695 - val_auc: 0.8953 - val_loss: 0.1706\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6494 - auc: 0.8731 - loss: 0.4576\n",
      "Epoch 1: val_auc improved from -inf to 0.80719, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3s/step - accuracy: 0.6495 - auc: 0.8732 - loss: 0.4571 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.2595 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6700 - auc: 0.9249 - loss: 0.2173\n",
      "Epoch 2: val_auc improved from 0.80719 to 0.80721, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 3s/step - accuracy: 0.6700 - auc: 0.9249 - loss: 0.2172 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3307 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7122 - auc: 0.9456 - loss: 0.1457\n",
      "Epoch 3: val_auc improved from 0.80721 to 0.84269, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 3s/step - accuracy: 0.7122 - auc: 0.9457 - loss: 0.1456 - val_accuracy: 0.6715 - val_auc: 0.8427 - val_loss: 0.7940 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7281 - auc: 0.9540 - loss: 0.1253\n",
      "Epoch 4: val_auc improved from 0.84269 to 0.94722, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 3s/step - accuracy: 0.7281 - auc: 0.9540 - loss: 0.1253 - val_accuracy: 0.7174 - val_auc: 0.9472 - val_loss: 0.1433 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7584 - auc: 0.9651 - loss: 0.0979\n",
      "Epoch 5: val_auc improved from 0.94722 to 0.97426, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 3s/step - accuracy: 0.7584 - auc: 0.9651 - loss: 0.0979 - val_accuracy: 0.8038 - val_auc: 0.9743 - val_loss: 0.0783 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7779 - auc: 0.9705 - loss: 0.0864\n",
      "Epoch 6: val_auc improved from 0.97426 to 0.97654, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 3s/step - accuracy: 0.7779 - auc: 0.9705 - loss: 0.0864 - val_accuracy: 0.8113 - val_auc: 0.9765 - val_loss: 0.0719 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7925 - auc: 0.9741 - loss: 0.0763\n",
      "Epoch 7: val_auc did not improve from 0.97654\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 3s/step - accuracy: 0.7925 - auc: 0.9741 - loss: 0.0763 - val_accuracy: 0.7928 - val_auc: 0.9721 - val_loss: 0.0853 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8154 - auc: 0.9786 - loss: 0.0687\n",
      "Epoch 8: val_auc improved from 0.97654 to 0.97674, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 3s/step - accuracy: 0.8154 - auc: 0.9786 - loss: 0.0687 - val_accuracy: 0.8088 - val_auc: 0.9767 - val_loss: 0.0707 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8252 - auc: 0.9808 - loss: 0.0625\n",
      "Epoch 9: val_auc improved from 0.97674 to 0.97927, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - accuracy: 0.8252 - auc: 0.9808 - loss: 0.0625 - val_accuracy: 0.8223 - val_auc: 0.9793 - val_loss: 0.0663 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8301 - auc: 0.9829 - loss: 0.0576\n",
      "Epoch 10: val_auc improved from 0.97927 to 0.98013, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 3s/step - accuracy: 0.8301 - auc: 0.9829 - loss: 0.0576 - val_accuracy: 0.8258 - val_auc: 0.9801 - val_loss: 0.0629 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8493 - auc: 0.9858 - loss: 0.0509\n",
      "Epoch 11: val_auc improved from 0.98013 to 0.98170, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 3s/step - accuracy: 0.8493 - auc: 0.9858 - loss: 0.0509 - val_accuracy: 0.8228 - val_auc: 0.9817 - val_loss: 0.0601 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8569 - auc: 0.9869 - loss: 0.0497\n",
      "Epoch 12: val_auc did not improve from 0.98170\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 3s/step - accuracy: 0.8569 - auc: 0.9869 - loss: 0.0497 - val_accuracy: 0.8208 - val_auc: 0.9795 - val_loss: 0.0658 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8606 - auc: 0.9882 - loss: 0.0445\n",
      "Epoch 13: val_auc improved from 0.98170 to 0.98193, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 3s/step - accuracy: 0.8606 - auc: 0.9882 - loss: 0.0445 - val_accuracy: 0.8392 - val_auc: 0.9819 - val_loss: 0.0613 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8767 - auc: 0.9900 - loss: 0.0399\n",
      "Epoch 14: val_auc improved from 0.98193 to 0.98262, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 3s/step - accuracy: 0.8767 - auc: 0.9900 - loss: 0.0399 - val_accuracy: 0.8347 - val_auc: 0.9826 - val_loss: 0.0604 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8783 - auc: 0.9912 - loss: 0.0366\n",
      "Epoch 15: val_auc improved from 0.98262 to 0.98366, saving model to resnet50_cbam_classificationhead_fold1_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 3s/step - accuracy: 0.8783 - auc: 0.9912 - loss: 0.0366 - val_accuracy: 0.8377 - val_auc: 0.9837 - val_loss: 0.0596 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8928 - auc: 0.9926 - loss: 0.0331\n",
      "Epoch 16: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 3s/step - accuracy: 0.8928 - auc: 0.9926 - loss: 0.0331 - val_accuracy: 0.8372 - val_auc: 0.9809 - val_loss: 0.0649 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9003 - auc: 0.9933 - loss: 0.0318\n",
      "Epoch 17: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 3s/step - accuracy: 0.9003 - auc: 0.9933 - loss: 0.0318 - val_accuracy: 0.8397 - val_auc: 0.9825 - val_loss: 0.0613 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9065 - auc: 0.9936 - loss: 0.0294\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 18: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 3s/step - accuracy: 0.9065 - auc: 0.9936 - loss: 0.0294 - val_accuracy: 0.8402 - val_auc: 0.9822 - val_loss: 0.0649 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9126 - auc: 0.9947 - loss: 0.0281\n",
      "Epoch 19: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 3s/step - accuracy: 0.9126 - auc: 0.9947 - loss: 0.0281 - val_accuracy: 0.8263 - val_auc: 0.9782 - val_loss: 0.0750 - learning_rate: 1.0000e-06\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9122 - auc: 0.9953 - loss: 0.0256\n",
      "Epoch 20: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 3s/step - accuracy: 0.9122 - auc: 0.9953 - loss: 0.0256 - val_accuracy: 0.8293 - val_auc: 0.9784 - val_loss: 0.0735 - learning_rate: 1.0000e-06\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9196 - auc: 0.9955 - loss: 0.0241\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 21: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 3s/step - accuracy: 0.9196 - auc: 0.9955 - loss: 0.0241 - val_accuracy: 0.8303 - val_auc: 0.9791 - val_loss: 0.0727 - learning_rate: 1.0000e-06\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9211 - auc: 0.9960 - loss: 0.0248\n",
      "Epoch 22: val_auc did not improve from 0.98366\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3s/step - accuracy: 0.9211 - auc: 0.9960 - loss: 0.0248 - val_accuracy: 0.8238 - val_auc: 0.9782 - val_loss: 0.0752 - learning_rate: 1.0000e-07\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "FOLD 1 - Loss: 0.0596, Accuracy: 0.8377, AUC: 0.9837\n",
      "\n",
      "\n",
      "===== FOLD 2/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/.local/share/virtualenvs/account-management-Kww3qb6U/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802ms/step - accuracy: 0.6223 - auc: 0.8405 - loss: 0.2229\n",
      "Epoch 1: val_auc improved from -inf to 0.88075, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 993ms/step - accuracy: 0.6225 - auc: 0.8406 - loss: 0.2228 - val_accuracy: 0.6695 - val_auc: 0.8807 - val_loss: 0.1719\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813ms/step - accuracy: 0.6688 - auc: 0.8694 - loss: 0.1946\n",
      "Epoch 2: val_auc improved from 0.88075 to 0.88589, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.6688 - auc: 0.8694 - loss: 0.1945 - val_accuracy: 0.6695 - val_auc: 0.8859 - val_loss: 0.1711\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - accuracy: 0.6756 - auc: 0.8746 - loss: 0.1845\n",
      "Epoch 3: val_auc improved from 0.88589 to 0.89034, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 1s/step - accuracy: 0.6756 - auc: 0.8746 - loss: 0.1845 - val_accuracy: 0.6695 - val_auc: 0.8903 - val_loss: 0.1738\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.6700 - auc: 0.8729 - loss: 0.1955\n",
      "Epoch 4: val_auc improved from 0.89034 to 0.89118, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.6700 - auc: 0.8729 - loss: 0.1955 - val_accuracy: 0.6695 - val_auc: 0.8912 - val_loss: 0.1727\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865ms/step - accuracy: 0.6698 - auc: 0.8744 - loss: 0.1961\n",
      "Epoch 5: val_auc did not improve from 0.89118\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.6698 - auc: 0.8744 - loss: 0.1960 - val_accuracy: 0.6695 - val_auc: 0.8907 - val_loss: 0.1708\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869ms/step - accuracy: 0.6782 - auc: 0.8819 - loss: 0.1758\n",
      "Epoch 6: val_auc did not improve from 0.89118\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - accuracy: 0.6781 - auc: 0.8819 - loss: 0.1758 - val_accuracy: 0.6690 - val_auc: 0.8912 - val_loss: 0.1701\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.6714 - auc: 0.8794 - loss: 0.1771\n",
      "Epoch 7: val_auc improved from 0.89118 to 0.89302, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.6714 - auc: 0.8794 - loss: 0.1772 - val_accuracy: 0.6695 - val_auc: 0.8930 - val_loss: 0.1705\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836ms/step - accuracy: 0.6782 - auc: 0.8823 - loss: 0.1730\n",
      "Epoch 8: val_auc improved from 0.89302 to 0.89372, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 1s/step - accuracy: 0.6782 - auc: 0.8823 - loss: 0.1731 - val_accuracy: 0.6700 - val_auc: 0.8937 - val_loss: 0.1707\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.6688 - auc: 0.8779 - loss: 0.1882\n",
      "Epoch 9: val_auc improved from 0.89372 to 0.89386, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 1s/step - accuracy: 0.6688 - auc: 0.8779 - loss: 0.1882 - val_accuracy: 0.6695 - val_auc: 0.8939 - val_loss: 0.1687\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856ms/step - accuracy: 0.6553 - auc: 0.8768 - loss: 0.1891\n",
      "Epoch 10: val_auc did not improve from 0.89386\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.6554 - auc: 0.8768 - loss: 0.1891 - val_accuracy: 0.6700 - val_auc: 0.8929 - val_loss: 0.1680\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895ms/step - accuracy: 0.6680 - auc: 0.8793 - loss: 0.1863\n",
      "Epoch 11: val_auc improved from 0.89386 to 0.89701, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.6680 - auc: 0.8793 - loss: 0.1863 - val_accuracy: 0.6700 - val_auc: 0.8970 - val_loss: 0.1669\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887ms/step - accuracy: 0.6676 - auc: 0.8823 - loss: 0.1829\n",
      "Epoch 12: val_auc improved from 0.89701 to 0.89982, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.6676 - auc: 0.8823 - loss: 0.1829 - val_accuracy: 0.6700 - val_auc: 0.8998 - val_loss: 0.1678\n",
      "Epoch 13/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.6741 - auc: 0.8846 - loss: 0.1753\n",
      "Epoch 13: val_auc improved from 0.89982 to 0.90024, saving model to resnet50_cbam_classificationhead_fold2_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.6741 - auc: 0.8845 - loss: 0.1754 - val_accuracy: 0.6700 - val_auc: 0.9002 - val_loss: 0.1664\n",
      "Epoch 14/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847ms/step - accuracy: 0.6776 - auc: 0.8861 - loss: 0.1715\n",
      "Epoch 14: val_auc did not improve from 0.90024\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.6775 - auc: 0.8861 - loss: 0.1715 - val_accuracy: 0.6700 - val_auc: 0.8963 - val_loss: 0.1667\n",
      "Epoch 15/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.6694 - auc: 0.8827 - loss: 0.1840\n",
      "Epoch 15: val_auc did not improve from 0.90024\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.6694 - auc: 0.8827 - loss: 0.1840 - val_accuracy: 0.6685 - val_auc: 0.8957 - val_loss: 0.1725\n",
      "Epoch 16/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - accuracy: 0.6761 - auc: 0.8834 - loss: 0.1821\n",
      "Epoch 16: val_auc did not improve from 0.90024\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.6761 - auc: 0.8834 - loss: 0.1822 - val_accuracy: 0.6700 - val_auc: 0.8974 - val_loss: 0.1663\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6536 - auc: 0.8494 - loss: 0.6992\n",
      "Epoch 1: val_auc improved from -inf to 0.80721, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 3s/step - accuracy: 0.6536 - auc: 0.8495 - loss: 0.6987 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3318 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6605 - auc: 0.9087 - loss: 0.3189\n",
      "Epoch 2: val_auc did not improve from 0.80721\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 3s/step - accuracy: 0.6605 - auc: 0.9087 - loss: 0.3187 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3289 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6890 - auc: 0.9284 - loss: 0.2084\n",
      "Epoch 3: val_auc improved from 0.80721 to 0.81499, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 3s/step - accuracy: 0.6890 - auc: 0.9284 - loss: 0.2082 - val_accuracy: 0.6695 - val_auc: 0.8150 - val_loss: 1.1508 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7166 - auc: 0.9501 - loss: 0.1278\n",
      "Epoch 4: val_auc improved from 0.81499 to 0.92793, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m854s\u001b[0m 3s/step - accuracy: 0.7166 - auc: 0.9501 - loss: 0.1278 - val_accuracy: 0.6835 - val_auc: 0.9279 - val_loss: 0.1867 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7412 - auc: 0.9582 - loss: 0.1106\n",
      "Epoch 5: val_auc improved from 0.92793 to 0.96764, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m845s\u001b[0m 3s/step - accuracy: 0.7413 - auc: 0.9582 - loss: 0.1106 - val_accuracy: 0.7808 - val_auc: 0.9676 - val_loss: 0.0908 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7543 - auc: 0.9646 - loss: 0.1009\n",
      "Epoch 6: val_auc improved from 0.96764 to 0.97294, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m874s\u001b[0m 3s/step - accuracy: 0.7543 - auc: 0.9646 - loss: 0.1009 - val_accuracy: 0.7933 - val_auc: 0.9729 - val_loss: 0.0778 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7655 - auc: 0.9672 - loss: 0.0904\n",
      "Epoch 7: val_auc improved from 0.97294 to 0.97600, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m877s\u001b[0m 3s/step - accuracy: 0.7655 - auc: 0.9672 - loss: 0.0903 - val_accuracy: 0.8083 - val_auc: 0.9760 - val_loss: 0.0709 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7979 - auc: 0.9740 - loss: 0.0746\n",
      "Epoch 8: val_auc did not improve from 0.97600\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m925s\u001b[0m 4s/step - accuracy: 0.7979 - auc: 0.9740 - loss: 0.0746 - val_accuracy: 0.8053 - val_auc: 0.9758 - val_loss: 0.0687 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8052 - auc: 0.9761 - loss: 0.0750\n",
      "Epoch 9: val_auc improved from 0.97600 to 0.97760, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 3s/step - accuracy: 0.8052 - auc: 0.9761 - loss: 0.0750 - val_accuracy: 0.8058 - val_auc: 0.9776 - val_loss: 0.0642 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8117 - auc: 0.9781 - loss: 0.0703\n",
      "Epoch 10: val_auc improved from 0.97760 to 0.97900, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 3s/step - accuracy: 0.8117 - auc: 0.9781 - loss: 0.0703 - val_accuracy: 0.8183 - val_auc: 0.9790 - val_loss: 0.0621 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8181 - auc: 0.9797 - loss: 0.0666\n",
      "Epoch 11: val_auc improved from 0.97900 to 0.98000, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 3s/step - accuracy: 0.8181 - auc: 0.9797 - loss: 0.0666 - val_accuracy: 0.8208 - val_auc: 0.9800 - val_loss: 0.0597 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8268 - auc: 0.9815 - loss: 0.0631\n",
      "Epoch 12: val_auc improved from 0.98000 to 0.98256, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 3s/step - accuracy: 0.8268 - auc: 0.9815 - loss: 0.0631 - val_accuracy: 0.8313 - val_auc: 0.9826 - val_loss: 0.0557 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8344 - auc: 0.9838 - loss: 0.0540\n",
      "Epoch 13: val_auc did not improve from 0.98256\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 3s/step - accuracy: 0.8344 - auc: 0.9838 - loss: 0.0540 - val_accuracy: 0.8263 - val_auc: 0.9805 - val_loss: 0.0584 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8485 - auc: 0.9847 - loss: 0.0548\n",
      "Epoch 14: val_auc did not improve from 0.98256\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 3s/step - accuracy: 0.8485 - auc: 0.9847 - loss: 0.0548 - val_accuracy: 0.8178 - val_auc: 0.9802 - val_loss: 0.0589 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8537 - auc: 0.9873 - loss: 0.0443\n",
      "Epoch 15: val_auc improved from 0.98256 to 0.98394, saving model to resnet50_cbam_classificationhead_fold2_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 3s/step - accuracy: 0.8537 - auc: 0.9873 - loss: 0.0443 - val_accuracy: 0.8417 - val_auc: 0.9839 - val_loss: 0.0524 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8699 - auc: 0.9893 - loss: 0.0410\n",
      "Epoch 16: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 3s/step - accuracy: 0.8699 - auc: 0.9893 - loss: 0.0410 - val_accuracy: 0.8183 - val_auc: 0.9802 - val_loss: 0.0614 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8722 - auc: 0.9900 - loss: 0.0419\n",
      "Epoch 17: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 3s/step - accuracy: 0.8722 - auc: 0.9900 - loss: 0.0419 - val_accuracy: 0.8308 - val_auc: 0.9811 - val_loss: 0.0608 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8796 - auc: 0.9903 - loss: 0.0380\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 18: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.8796 - auc: 0.9903 - loss: 0.0380 - val_accuracy: 0.8407 - val_auc: 0.9835 - val_loss: 0.0546 - learning_rate: 1.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8958 - auc: 0.9925 - loss: 0.0326\n",
      "Epoch 19: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.8958 - auc: 0.9925 - loss: 0.0326 - val_accuracy: 0.8372 - val_auc: 0.9829 - val_loss: 0.0556 - learning_rate: 1.0000e-06\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8946 - auc: 0.9932 - loss: 0.0297\n",
      "Epoch 20: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8946 - auc: 0.9932 - loss: 0.0297 - val_accuracy: 0.8362 - val_auc: 0.9825 - val_loss: 0.0570 - learning_rate: 1.0000e-06\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8883 - auc: 0.9922 - loss: 0.0337\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 21: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.8883 - auc: 0.9922 - loss: 0.0337 - val_accuracy: 0.8367 - val_auc: 0.9831 - val_loss: 0.0557 - learning_rate: 1.0000e-06\n",
      "Epoch 22/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8883 - auc: 0.9926 - loss: 0.0328\n",
      "Epoch 22: val_auc did not improve from 0.98394\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - accuracy: 0.8884 - auc: 0.9926 - loss: 0.0328 - val_accuracy: 0.8377 - val_auc: 0.9831 - val_loss: 0.0553 - learning_rate: 1.0000e-07\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "FOLD 2 - Loss: 0.0524, Accuracy: 0.8417, AUC: 0.9839\n",
      "\n",
      "\n",
      "===== FOLD 3/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       891\n",
      "bkl       879\n",
      "bcc       411\n",
      "akiec     262\n",
      "vasc      113\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       222\n",
      "bkl       220\n",
      "bcc       103\n",
      "akiec      65\n",
      "vasc       29\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/.local/share/virtualenvs/account-management-Kww3qb6U/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776ms/step - accuracy: 0.6263 - auc: 0.8485 - loss: 0.2221\n",
      "Epoch 1: val_auc improved from -inf to 0.88296, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 960ms/step - accuracy: 0.6264 - auc: 0.8486 - loss: 0.2220 - val_accuracy: 0.6695 - val_auc: 0.8830 - val_loss: 0.1738\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - accuracy: 0.6746 - auc: 0.8753 - loss: 0.1819\n",
      "Epoch 2: val_auc improved from 0.88296 to 0.88977, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 959ms/step - accuracy: 0.6746 - auc: 0.8753 - loss: 0.1819 - val_accuracy: 0.6695 - val_auc: 0.8898 - val_loss: 0.1733\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.6752 - auc: 0.8770 - loss: 0.1800\n",
      "Epoch 3: val_auc improved from 0.88977 to 0.88994, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 961ms/step - accuracy: 0.6751 - auc: 0.8770 - loss: 0.1800 - val_accuracy: 0.6695 - val_auc: 0.8899 - val_loss: 0.1768\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.6812 - auc: 0.8810 - loss: 0.1798\n",
      "Epoch 4: val_auc did not improve from 0.88994\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 954ms/step - accuracy: 0.6811 - auc: 0.8810 - loss: 0.1798 - val_accuracy: 0.6695 - val_auc: 0.8889 - val_loss: 0.1714\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.6729 - auc: 0.8817 - loss: 0.1729\n",
      "Epoch 5: val_auc improved from 0.88994 to 0.89050, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 958ms/step - accuracy: 0.6728 - auc: 0.8817 - loss: 0.1730 - val_accuracy: 0.6695 - val_auc: 0.8905 - val_loss: 0.1705\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - accuracy: 0.6702 - auc: 0.8790 - loss: 0.1839\n",
      "Epoch 6: val_auc improved from 0.89050 to 0.89454, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 955ms/step - accuracy: 0.6702 - auc: 0.8790 - loss: 0.1839 - val_accuracy: 0.6695 - val_auc: 0.8945 - val_loss: 0.1701\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788ms/step - accuracy: 0.6719 - auc: 0.8793 - loss: 0.1852\n",
      "Epoch 7: val_auc did not improve from 0.89454\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 971ms/step - accuracy: 0.6719 - auc: 0.8793 - loss: 0.1852 - val_accuracy: 0.6695 - val_auc: 0.8921 - val_loss: 0.1694\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785ms/step - accuracy: 0.6729 - auc: 0.8800 - loss: 0.1840\n",
      "Epoch 8: val_auc improved from 0.89454 to 0.89917, saving model to resnet50_cbam_classificationhead_fold3_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 964ms/step - accuracy: 0.6729 - auc: 0.8800 - loss: 0.1840 - val_accuracy: 0.6695 - val_auc: 0.8992 - val_loss: 0.1704\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - accuracy: 0.6675 - auc: 0.8795 - loss: 0.1829\n",
      "Epoch 9: val_auc did not improve from 0.89917\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 975ms/step - accuracy: 0.6675 - auc: 0.8795 - loss: 0.1829 - val_accuracy: 0.6695 - val_auc: 0.8908 - val_loss: 0.1705\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788ms/step - accuracy: 0.6710 - auc: 0.8825 - loss: 0.1827\n",
      "Epoch 10: val_auc did not improve from 0.89917\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 968ms/step - accuracy: 0.6710 - auc: 0.8825 - loss: 0.1827 - val_accuracy: 0.6700 - val_auc: 0.8928 - val_loss: 0.1701\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782ms/step - accuracy: 0.6629 - auc: 0.8774 - loss: 0.1897\n",
      "Epoch 11: val_auc did not improve from 0.89917\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 960ms/step - accuracy: 0.6630 - auc: 0.8774 - loss: 0.1897 - val_accuracy: 0.6700 - val_auc: 0.8983 - val_loss: 0.1687\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6494 - auc: 0.8574 - loss: 0.5585\n",
      "Epoch 1: val_auc improved from -inf to 0.80721, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 3s/step - accuracy: 0.6494 - auc: 0.8575 - loss: 0.5579 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3318 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6639 - auc: 0.9236 - loss: 0.2016\n",
      "Epoch 2: val_auc improved from 0.80721 to 0.80721, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 3s/step - accuracy: 0.6639 - auc: 0.9236 - loss: 0.2015 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3305 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7228 - auc: 0.9523 - loss: 0.1218\n",
      "Epoch 3: val_auc improved from 0.80721 to 0.82924, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.7228 - auc: 0.9523 - loss: 0.1218 - val_accuracy: 0.6695 - val_auc: 0.8292 - val_loss: 0.9901 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7509 - auc: 0.9614 - loss: 0.1020\n",
      "Epoch 4: val_auc improved from 0.82924 to 0.94036, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.7509 - auc: 0.9614 - loss: 0.1020 - val_accuracy: 0.6955 - val_auc: 0.9404 - val_loss: 0.1485 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7712 - auc: 0.9685 - loss: 0.0908\n",
      "Epoch 5: val_auc improved from 0.94036 to 0.97079, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 3s/step - accuracy: 0.7712 - auc: 0.9685 - loss: 0.0908 - val_accuracy: 0.7953 - val_auc: 0.9708 - val_loss: 0.0850 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8009 - auc: 0.9744 - loss: 0.0759\n",
      "Epoch 6: val_auc improved from 0.97079 to 0.97481, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.8009 - auc: 0.9744 - loss: 0.0759 - val_accuracy: 0.7988 - val_auc: 0.9748 - val_loss: 0.0759 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8079 - auc: 0.9784 - loss: 0.0666\n",
      "Epoch 7: val_auc improved from 0.97481 to 0.97571, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8079 - auc: 0.9784 - loss: 0.0666 - val_accuracy: 0.8003 - val_auc: 0.9757 - val_loss: 0.0715 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8180 - auc: 0.9797 - loss: 0.0661\n",
      "Epoch 8: val_auc improved from 0.97571 to 0.97612, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 3s/step - accuracy: 0.8179 - auc: 0.9797 - loss: 0.0661 - val_accuracy: 0.8038 - val_auc: 0.9761 - val_loss: 0.0694 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8257 - auc: 0.9803 - loss: 0.0628\n",
      "Epoch 9: val_auc improved from 0.97612 to 0.97795, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 3s/step - accuracy: 0.8258 - auc: 0.9803 - loss: 0.0628 - val_accuracy: 0.8073 - val_auc: 0.9779 - val_loss: 0.0659 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8466 - auc: 0.9845 - loss: 0.0554\n",
      "Epoch 10: val_auc improved from 0.97795 to 0.97869, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.8466 - auc: 0.9845 - loss: 0.0553 - val_accuracy: 0.8168 - val_auc: 0.9787 - val_loss: 0.0644 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8567 - auc: 0.9862 - loss: 0.0497\n",
      "Epoch 11: val_auc did not improve from 0.97869\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 3s/step - accuracy: 0.8567 - auc: 0.9862 - loss: 0.0497 - val_accuracy: 0.8173 - val_auc: 0.9761 - val_loss: 0.0693 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8689 - auc: 0.9883 - loss: 0.0448\n",
      "Epoch 12: val_auc improved from 0.97869 to 0.97927, saving model to resnet50_cbam_classificationhead_fold3_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.8689 - auc: 0.9883 - loss: 0.0448 - val_accuracy: 0.8263 - val_auc: 0.9793 - val_loss: 0.0647 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8823 - auc: 0.9903 - loss: 0.0386\n",
      "Epoch 13: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 3s/step - accuracy: 0.8823 - auc: 0.9902 - loss: 0.0386 - val_accuracy: 0.8243 - val_auc: 0.9789 - val_loss: 0.0677 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8769 - auc: 0.9906 - loss: 0.0390\n",
      "Epoch 14: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.8770 - auc: 0.9906 - loss: 0.0390 - val_accuracy: 0.8208 - val_auc: 0.9790 - val_loss: 0.0682 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8881 - auc: 0.9916 - loss: 0.0357\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 15: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 3s/step - accuracy: 0.8881 - auc: 0.9916 - loss: 0.0357 - val_accuracy: 0.8357 - val_auc: 0.9789 - val_loss: 0.0666 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8984 - auc: 0.9935 - loss: 0.0311\n",
      "Epoch 16: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8984 - auc: 0.9935 - loss: 0.0311 - val_accuracy: 0.8088 - val_auc: 0.9745 - val_loss: 0.0774 - learning_rate: 1.0000e-06\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8975 - auc: 0.9932 - loss: 0.0311\n",
      "Epoch 17: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 3s/step - accuracy: 0.8975 - auc: 0.9932 - loss: 0.0311 - val_accuracy: 0.8148 - val_auc: 0.9754 - val_loss: 0.0764 - learning_rate: 1.0000e-06\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8998 - auc: 0.9937 - loss: 0.0287\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 18: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 3s/step - accuracy: 0.8998 - auc: 0.9937 - loss: 0.0287 - val_accuracy: 0.8073 - val_auc: 0.9744 - val_loss: 0.0791 - learning_rate: 1.0000e-06\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9027 - auc: 0.9937 - loss: 0.0302\n",
      "Epoch 19: val_auc did not improve from 0.97927\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.9027 - auc: 0.9937 - loss: 0.0302 - val_accuracy: 0.8108 - val_auc: 0.9749 - val_loss: 0.0774 - learning_rate: 1.0000e-07\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "FOLD 3 - Loss: 0.0647, Accuracy: 0.8263, AUC: 0.9793\n",
      "\n",
      "\n",
      "===== FOLD 4/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       891\n",
      "bkl       879\n",
      "bcc       412\n",
      "akiec     261\n",
      "vasc      113\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       222\n",
      "bkl       220\n",
      "bcc       102\n",
      "akiec      66\n",
      "vasc       29\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/.local/share/virtualenvs/account-management-Kww3qb6U/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769ms/step - accuracy: 0.6307 - auc: 0.8602 - loss: 0.2040\n",
      "Epoch 1: val_auc improved from -inf to 0.88024, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 950ms/step - accuracy: 0.6308 - auc: 0.8602 - loss: 0.2039 - val_accuracy: 0.6695 - val_auc: 0.8802 - val_loss: 0.1730\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: 0.6729 - auc: 0.8736 - loss: 0.1871\n",
      "Epoch 2: val_auc improved from 0.88024 to 0.88924, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 946ms/step - accuracy: 0.6729 - auc: 0.8736 - loss: 0.1871 - val_accuracy: 0.6695 - val_auc: 0.8892 - val_loss: 0.1720\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769ms/step - accuracy: 0.6609 - auc: 0.8712 - loss: 0.1919\n",
      "Epoch 3: val_auc did not improve from 0.88924\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 941ms/step - accuracy: 0.6609 - auc: 0.8712 - loss: 0.1919 - val_accuracy: 0.6695 - val_auc: 0.8885 - val_loss: 0.1720\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.6782 - auc: 0.8784 - loss: 0.1837\n",
      "Epoch 4: val_auc improved from 0.88924 to 0.89089, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 952ms/step - accuracy: 0.6781 - auc: 0.8784 - loss: 0.1837 - val_accuracy: 0.6695 - val_auc: 0.8909 - val_loss: 0.1719\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.6686 - auc: 0.8754 - loss: 0.1842\n",
      "Epoch 5: val_auc improved from 0.89089 to 0.89094, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 951ms/step - accuracy: 0.6686 - auc: 0.8754 - loss: 0.1843 - val_accuracy: 0.6695 - val_auc: 0.8909 - val_loss: 0.1739\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.6742 - auc: 0.8772 - loss: 0.1876\n",
      "Epoch 6: val_auc did not improve from 0.89094\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 948ms/step - accuracy: 0.6742 - auc: 0.8772 - loss: 0.1876 - val_accuracy: 0.6695 - val_auc: 0.8908 - val_loss: 0.1714\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.6702 - auc: 0.8759 - loss: 0.1932\n",
      "Epoch 7: val_auc improved from 0.89094 to 0.89232, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 949ms/step - accuracy: 0.6702 - auc: 0.8759 - loss: 0.1932 - val_accuracy: 0.6695 - val_auc: 0.8923 - val_loss: 0.1712\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.6691 - auc: 0.8782 - loss: 0.1852\n",
      "Epoch 8: val_auc improved from 0.89232 to 0.89252, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 958ms/step - accuracy: 0.6691 - auc: 0.8782 - loss: 0.1852 - val_accuracy: 0.6695 - val_auc: 0.8925 - val_loss: 0.1701\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.6706 - auc: 0.8793 - loss: 0.1850\n",
      "Epoch 9: val_auc improved from 0.89252 to 0.89907, saving model to resnet50_cbam_classificationhead_fold4_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 950ms/step - accuracy: 0.6706 - auc: 0.8793 - loss: 0.1850 - val_accuracy: 0.6695 - val_auc: 0.8991 - val_loss: 0.1699\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.6706 - auc: 0.8804 - loss: 0.1879\n",
      "Epoch 10: val_auc did not improve from 0.89907\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 957ms/step - accuracy: 0.6706 - auc: 0.8804 - loss: 0.1879 - val_accuracy: 0.6695 - val_auc: 0.8987 - val_loss: 0.1700\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782ms/step - accuracy: 0.6680 - auc: 0.8759 - loss: 0.1948\n",
      "Epoch 11: val_auc did not improve from 0.89907\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 960ms/step - accuracy: 0.6680 - auc: 0.8759 - loss: 0.1948 - val_accuracy: 0.6695 - val_auc: 0.8895 - val_loss: 0.1724\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.6733 - auc: 0.8830 - loss: 0.1776\n",
      "Epoch 12: val_auc did not improve from 0.89907\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 960ms/step - accuracy: 0.6732 - auc: 0.8830 - loss: 0.1776 - val_accuracy: 0.6695 - val_auc: 0.8967 - val_loss: 0.1695\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5938 - auc: 0.8586 - loss: 0.5001\n",
      "Epoch 1: val_auc improved from -inf to 0.80721, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - accuracy: 0.5939 - auc: 0.8586 - loss: 0.4997 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3318 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6699 - auc: 0.9186 - loss: 0.2387\n",
      "Epoch 2: val_auc did not improve from 0.80721\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.6699 - auc: 0.9186 - loss: 0.2386 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3311 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7025 - auc: 0.9453 - loss: 0.1366\n",
      "Epoch 3: val_auc improved from 0.80721 to 0.81480, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.7025 - auc: 0.9453 - loss: 0.1366 - val_accuracy: 0.6670 - val_auc: 0.8148 - val_loss: 1.2077 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7523 - auc: 0.9610 - loss: 0.1048\n",
      "Epoch 4: val_auc improved from 0.81480 to 0.91797, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 3s/step - accuracy: 0.7523 - auc: 0.9610 - loss: 0.1048 - val_accuracy: 0.6131 - val_auc: 0.9180 - val_loss: 0.1455 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7724 - auc: 0.9681 - loss: 0.0890\n",
      "Epoch 5: val_auc improved from 0.91797 to 0.97039, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.7724 - auc: 0.9681 - loss: 0.0890 - val_accuracy: 0.7863 - val_auc: 0.9704 - val_loss: 0.0828 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7883 - auc: 0.9722 - loss: 0.0811\n",
      "Epoch 6: val_auc improved from 0.97039 to 0.97601, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.7883 - auc: 0.9722 - loss: 0.0811 - val_accuracy: 0.8058 - val_auc: 0.9760 - val_loss: 0.0715 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8119 - auc: 0.9773 - loss: 0.0689\n",
      "Epoch 7: val_auc did not improve from 0.97601\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.8118 - auc: 0.9773 - loss: 0.0689 - val_accuracy: 0.8108 - val_auc: 0.9759 - val_loss: 0.0709 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8196 - auc: 0.9794 - loss: 0.0644\n",
      "Epoch 8: val_auc improved from 0.97601 to 0.97825, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8196 - auc: 0.9794 - loss: 0.0644 - val_accuracy: 0.8118 - val_auc: 0.9783 - val_loss: 0.0662 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8277 - auc: 0.9817 - loss: 0.0581\n",
      "Epoch 9: val_auc improved from 0.97825 to 0.97936, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.8278 - auc: 0.9817 - loss: 0.0581 - val_accuracy: 0.8238 - val_auc: 0.9794 - val_loss: 0.0643 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8458 - auc: 0.9846 - loss: 0.0506\n",
      "Epoch 10: val_auc improved from 0.97936 to 0.97947, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8457 - auc: 0.9846 - loss: 0.0506 - val_accuracy: 0.8218 - val_auc: 0.9795 - val_loss: 0.0639 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8442 - auc: 0.9853 - loss: 0.0498\n",
      "Epoch 11: val_auc improved from 0.97947 to 0.98014, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8442 - auc: 0.9853 - loss: 0.0499 - val_accuracy: 0.8228 - val_auc: 0.9801 - val_loss: 0.0620 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8559 - auc: 0.9871 - loss: 0.0456\n",
      "Epoch 12: val_auc improved from 0.98014 to 0.98097, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8559 - auc: 0.9871 - loss: 0.0456 - val_accuracy: 0.8283 - val_auc: 0.9810 - val_loss: 0.0610 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8590 - auc: 0.9884 - loss: 0.0433\n",
      "Epoch 13: val_auc improved from 0.98097 to 0.98106, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8590 - auc: 0.9884 - loss: 0.0433 - val_accuracy: 0.8293 - val_auc: 0.9811 - val_loss: 0.0620 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8686 - auc: 0.9895 - loss: 0.0410\n",
      "Epoch 14: val_auc improved from 0.98106 to 0.98247, saving model to resnet50_cbam_classificationhead_fold4_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 3s/step - accuracy: 0.8686 - auc: 0.9895 - loss: 0.0410 - val_accuracy: 0.8382 - val_auc: 0.9825 - val_loss: 0.0582 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8831 - auc: 0.9914 - loss: 0.0350\n",
      "Epoch 15: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 3s/step - accuracy: 0.8831 - auc: 0.9914 - loss: 0.0350 - val_accuracy: 0.8193 - val_auc: 0.9796 - val_loss: 0.0639 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8821 - auc: 0.9923 - loss: 0.0322\n",
      "Epoch 16: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.8821 - auc: 0.9923 - loss: 0.0322 - val_accuracy: 0.8427 - val_auc: 0.9822 - val_loss: 0.0612 - learning_rate: 1.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9045 - auc: 0.9935 - loss: 0.0300\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 17: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 3s/step - accuracy: 0.9045 - auc: 0.9935 - loss: 0.0300 - val_accuracy: 0.8337 - val_auc: 0.9805 - val_loss: 0.0624 - learning_rate: 1.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9150 - auc: 0.9956 - loss: 0.0232\n",
      "Epoch 18: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 3s/step - accuracy: 0.9150 - auc: 0.9956 - loss: 0.0232 - val_accuracy: 0.8333 - val_auc: 0.9809 - val_loss: 0.0633 - learning_rate: 1.0000e-06\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9098 - auc: 0.9946 - loss: 0.0266\n",
      "Epoch 19: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 3s/step - accuracy: 0.9098 - auc: 0.9946 - loss: 0.0266 - val_accuracy: 0.8382 - val_auc: 0.9813 - val_loss: 0.0619 - learning_rate: 1.0000e-06\n",
      "Epoch 20/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9152 - auc: 0.9952 - loss: 0.0242\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 20: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.9152 - auc: 0.9952 - loss: 0.0242 - val_accuracy: 0.8382 - val_auc: 0.9814 - val_loss: 0.0626 - learning_rate: 1.0000e-06\n",
      "Epoch 21/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9175 - auc: 0.9960 - loss: 0.0216\n",
      "Epoch 21: val_auc did not improve from 0.98247\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.9174 - auc: 0.9960 - loss: 0.0216 - val_accuracy: 0.8397 - val_auc: 0.9815 - val_loss: 0.0624 - learning_rate: 1.0000e-07\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "FOLD 4 - Loss: 0.0582, Accuracy: 0.8382, AUC: 0.9825\n",
      "\n",
      "\n",
      "===== FOLD 5/5 =====\n",
      "Train size: 8012 Val size: 2003\n",
      "Train distribution:\n",
      " dx\n",
      "nv       5364\n",
      "mel       890\n",
      "bkl       880\n",
      "bcc       411\n",
      "akiec     261\n",
      "vasc      114\n",
      "df         92\n",
      "Name: count, dtype: int64\n",
      "Val distribution:\n",
      " dx\n",
      "nv       1341\n",
      "mel       223\n",
      "bkl       219\n",
      "bcc       103\n",
      "akiec      66\n",
      "vasc       28\n",
      "df         23\n",
      "Name: count, dtype: int64\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robp/.local/share/virtualenvs/account-management-Kww3qb6U/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: 0.6466 - auc: 0.8665 - loss: 0.1961\n",
      "Epoch 1: val_auc improved from -inf to 0.88720, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 954ms/step - accuracy: 0.6467 - auc: 0.8665 - loss: 0.1961 - val_accuracy: 0.6695 - val_auc: 0.8872 - val_loss: 0.1735\n",
      "Epoch 2/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - accuracy: 0.6740 - auc: 0.8730 - loss: 0.1912\n",
      "Epoch 2: val_auc improved from 0.88720 to 0.88946, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 953ms/step - accuracy: 0.6740 - auc: 0.8730 - loss: 0.1912 - val_accuracy: 0.6695 - val_auc: 0.8895 - val_loss: 0.1717\n",
      "Epoch 3/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.6852 - auc: 0.8825 - loss: 0.1691\n",
      "Epoch 3: val_auc improved from 0.88946 to 0.89154, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 956ms/step - accuracy: 0.6852 - auc: 0.8825 - loss: 0.1692 - val_accuracy: 0.6695 - val_auc: 0.8915 - val_loss: 0.1715\n",
      "Epoch 4/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784ms/step - accuracy: 0.6663 - auc: 0.8755 - loss: 0.1894\n",
      "Epoch 4: val_auc improved from 0.89154 to 0.89356, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 961ms/step - accuracy: 0.6664 - auc: 0.8755 - loss: 0.1893 - val_accuracy: 0.6695 - val_auc: 0.8936 - val_loss: 0.1698\n",
      "Epoch 5/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - accuracy: 0.6767 - auc: 0.8808 - loss: 0.1779\n",
      "Epoch 5: val_auc did not improve from 0.89356\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 955ms/step - accuracy: 0.6767 - auc: 0.8808 - loss: 0.1779 - val_accuracy: 0.6695 - val_auc: 0.8933 - val_loss: 0.1711\n",
      "Epoch 6/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - accuracy: 0.6615 - auc: 0.8762 - loss: 0.1912\n",
      "Epoch 6: val_auc did not improve from 0.89356\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 958ms/step - accuracy: 0.6615 - auc: 0.8762 - loss: 0.1912 - val_accuracy: 0.6695 - val_auc: 0.8929 - val_loss: 0.1698\n",
      "Epoch 7/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785ms/step - accuracy: 0.6739 - auc: 0.8813 - loss: 0.1810\n",
      "Epoch 7: val_auc improved from 0.89356 to 0.89432, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 962ms/step - accuracy: 0.6739 - auc: 0.8813 - loss: 0.1810 - val_accuracy: 0.6695 - val_auc: 0.8943 - val_loss: 0.1708\n",
      "Epoch 8/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.6839 - auc: 0.8851 - loss: 0.1721\n",
      "Epoch 8: val_auc improved from 0.89432 to 0.89781, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 954ms/step - accuracy: 0.6838 - auc: 0.8851 - loss: 0.1722 - val_accuracy: 0.6695 - val_auc: 0.8978 - val_loss: 0.1692\n",
      "Epoch 9/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - accuracy: 0.6572 - auc: 0.8774 - loss: 0.1930\n",
      "Epoch 9: val_auc improved from 0.89781 to 0.90248, saving model to resnet50_cbam_classificationhead_fold5_phase1.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 947ms/step - accuracy: 0.6573 - auc: 0.8775 - loss: 0.1930 - val_accuracy: 0.6695 - val_auc: 0.9025 - val_loss: 0.1687\n",
      "Epoch 10/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.6616 - auc: 0.8778 - loss: 0.1900\n",
      "Epoch 10: val_auc did not improve from 0.90248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 954ms/step - accuracy: 0.6617 - auc: 0.8779 - loss: 0.1900 - val_accuracy: 0.6695 - val_auc: 0.8943 - val_loss: 0.1708\n",
      "Epoch 11/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.6714 - auc: 0.8793 - loss: 0.1912\n",
      "Epoch 11: val_auc did not improve from 0.90248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 952ms/step - accuracy: 0.6713 - auc: 0.8793 - loss: 0.1912 - val_accuracy: 0.6690 - val_auc: 0.8972 - val_loss: 0.1667\n",
      "Epoch 12/20\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786ms/step - accuracy: 0.6745 - auc: 0.8867 - loss: 0.1751\n",
      "Epoch 12: val_auc did not improve from 0.90248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 960ms/step - accuracy: 0.6744 - auc: 0.8866 - loss: 0.1752 - val_accuracy: 0.6690 - val_auc: 0.8987 - val_loss: 0.1661\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6595 - auc: 0.8528 - loss: 0.7593\n",
      "Epoch 1: val_auc improved from -inf to 0.80721, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 3s/step - accuracy: 0.6595 - auc: 0.8529 - loss: 0.7583 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3318 - learning_rate: 1.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6602 - auc: 0.9201 - loss: 0.2346\n",
      "Epoch 2: val_auc did not improve from 0.80721\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 3s/step - accuracy: 0.6603 - auc: 0.9201 - loss: 0.2344 - val_accuracy: 0.6695 - val_auc: 0.8072 - val_loss: 1.3293 - learning_rate: 1.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7025 - auc: 0.9411 - loss: 0.1464\n",
      "Epoch 3: val_auc improved from 0.80721 to 0.81242, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 3s/step - accuracy: 0.7025 - auc: 0.9411 - loss: 0.1464 - val_accuracy: 0.6695 - val_auc: 0.8124 - val_loss: 1.2453 - learning_rate: 1.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7378 - auc: 0.9575 - loss: 0.1082\n",
      "Epoch 4: val_auc improved from 0.81242 to 0.94210, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 3s/step - accuracy: 0.7378 - auc: 0.9576 - loss: 0.1082 - val_accuracy: 0.7044 - val_auc: 0.9421 - val_loss: 0.1377 - learning_rate: 1.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7601 - auc: 0.9643 - loss: 0.0990\n",
      "Epoch 5: val_auc improved from 0.94210 to 0.97392, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - accuracy: 0.7601 - auc: 0.9643 - loss: 0.0990 - val_accuracy: 0.8008 - val_auc: 0.9739 - val_loss: 0.0765 - learning_rate: 1.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7815 - auc: 0.9694 - loss: 0.0827\n",
      "Epoch 6: val_auc improved from 0.97392 to 0.97849, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 3s/step - accuracy: 0.7815 - auc: 0.9694 - loss: 0.0827 - val_accuracy: 0.8183 - val_auc: 0.9785 - val_loss: 0.0664 - learning_rate: 1.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7883 - auc: 0.9726 - loss: 0.0811\n",
      "Epoch 7: val_auc improved from 0.97849 to 0.97944, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 3s/step - accuracy: 0.7884 - auc: 0.9726 - loss: 0.0811 - val_accuracy: 0.8183 - val_auc: 0.9794 - val_loss: 0.0630 - learning_rate: 1.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8122 - auc: 0.9768 - loss: 0.0740\n",
      "Epoch 8: val_auc improved from 0.97944 to 0.97964, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 3s/step - accuracy: 0.8122 - auc: 0.9768 - loss: 0.0740 - val_accuracy: 0.8218 - val_auc: 0.9796 - val_loss: 0.0619 - learning_rate: 1.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8190 - auc: 0.9800 - loss: 0.0625\n",
      "Epoch 9: val_auc improved from 0.97964 to 0.98095, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 3s/step - accuracy: 0.8190 - auc: 0.9800 - loss: 0.0625 - val_accuracy: 0.8268 - val_auc: 0.9809 - val_loss: 0.0593 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8312 - auc: 0.9817 - loss: 0.0569\n",
      "Epoch 10: val_auc improved from 0.98095 to 0.98119, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.8312 - auc: 0.9817 - loss: 0.0569 - val_accuracy: 0.8258 - val_auc: 0.9812 - val_loss: 0.0591 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8452 - auc: 0.9839 - loss: 0.0534\n",
      "Epoch 11: val_auc improved from 0.98119 to 0.98160, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8452 - auc: 0.9839 - loss: 0.0534 - val_accuracy: 0.8337 - val_auc: 0.9816 - val_loss: 0.0582 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8500 - auc: 0.9868 - loss: 0.0480\n",
      "Epoch 12: val_auc improved from 0.98160 to 0.98248, saving model to resnet50_cbam_classificationhead_fold5_phase2.keras\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8500 - auc: 0.9868 - loss: 0.0480 - val_accuracy: 0.8362 - val_auc: 0.9825 - val_loss: 0.0567 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8593 - auc: 0.9870 - loss: 0.0498\n",
      "Epoch 13: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8593 - auc: 0.9870 - loss: 0.0498 - val_accuracy: 0.8293 - val_auc: 0.9811 - val_loss: 0.0612 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8650 - auc: 0.9886 - loss: 0.0435\n",
      "Epoch 14: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.8650 - auc: 0.9886 - loss: 0.0435 - val_accuracy: 0.8362 - val_auc: 0.9816 - val_loss: 0.0578 - learning_rate: 1.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8755 - auc: 0.9899 - loss: 0.0398\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 15: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 3s/step - accuracy: 0.8755 - auc: 0.9899 - loss: 0.0398 - val_accuracy: 0.8273 - val_auc: 0.9808 - val_loss: 0.0624 - learning_rate: 1.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8885 - auc: 0.9916 - loss: 0.0352\n",
      "Epoch 16: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 3s/step - accuracy: 0.8885 - auc: 0.9916 - loss: 0.0352 - val_accuracy: 0.8223 - val_auc: 0.9804 - val_loss: 0.0624 - learning_rate: 1.0000e-06\n",
      "Epoch 17/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8901 - auc: 0.9921 - loss: 0.0355\n",
      "Epoch 17: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 3s/step - accuracy: 0.8902 - auc: 0.9921 - loss: 0.0355 - val_accuracy: 0.8248 - val_auc: 0.9811 - val_loss: 0.0605 - learning_rate: 1.0000e-06\n",
      "Epoch 18/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8857 - auc: 0.9915 - loss: 0.0358\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 18: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 3s/step - accuracy: 0.8857 - auc: 0.9915 - loss: 0.0358 - val_accuracy: 0.8238 - val_auc: 0.9812 - val_loss: 0.0609 - learning_rate: 1.0000e-06\n",
      "Epoch 19/200\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8956 - auc: 0.9929 - loss: 0.0327\n",
      "Epoch 19: val_auc did not improve from 0.98248\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 3s/step - accuracy: 0.8956 - auc: 0.9929 - loss: 0.0327 - val_accuracy: 0.8273 - val_auc: 0.9813 - val_loss: 0.0607 - learning_rate: 1.0000e-07\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "FOLD 5 - Loss: 0.0567, Accuracy: 0.8362, AUC: 0.9825\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "Average Loss over 5 folds  : 0.0583 (± 0.0040)\n",
      "Average Accuracy over 5 folds: 0.8360 (± 0.0052)\n",
      "Average AUC over 5 folds     : 0.9824 (± 0.0017)\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# For tracking the best fold, to later evaluate performance\n",
    "best_fold = None\n",
    "best_auc_across_folds = 0.0\n",
    "\n",
    "# For collecting metrics across folds\n",
    "fold_accuracies = []\n",
    "fold_aucs = []\n",
    "fold_losses = []\n",
    "\n",
    "# Epochs for each phase\n",
    "EPOCHS_PHASE1 = 20   # Freeze the backbone\n",
    "EPOCHS_PHASE2 = 200  # Fine-tuning\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "base_resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=None)\n",
    "\n",
    "# Data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen_val = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Get unique class labels (strings)\n",
    "all_class_labels = sorted(df['dx'].unique())\n",
    "\n",
    "# Compute global class weights for the entire dataset\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(all_class_labels),\n",
    "    y=df['dx'].values\n",
    ")\n",
    "# Map to dictionary: {class_index: weight}\n",
    "class_weights_dict = {}\n",
    "for label, w in zip(all_class_labels, class_weights_array):\n",
    "    # Index of this label in the alphabetical-sorted list\n",
    "    idx = all_class_labels.index(label)\n",
    "    class_weights_dict[idx] = w\n",
    "print(\"Class weights dict:\", class_weights_dict)\n",
    "\n",
    "fold_index = 1\n",
    "for train_idx, val_idx in skf.split(df, df['dx']):\n",
    "    print(f\"\\n\\n===== FOLD {fold_index}/{k_folds} =====\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.1) CREATE DATAFRAMES FOR THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "    print(\"Train distribution:\\n\", train_df['dx'].value_counts())\n",
    "    print(\"Val distribution:\\n\", val_df['dx'].value_counts())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.2) FLOW FROM DATAFRAME: TRAIN & VAL\n",
    "    # ------------------------------------------------------\n",
    "    train_generator = datagen_train.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_generator = datagen_val.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='image_path',\n",
    "        y_col='dx',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Extract class names from the train_generator\n",
    "    # The generator creates an internal mapping of classes -> indices\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.3) BUILD & COMPILE MODEL FROM SCRATCH FOR EACH FOLD\n",
    "    # ------------------------------------------------------\n",
    "    custom_resnet = build_resnet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "    # Transfer weights from base Keras ResNet50 (ImageNet) to custom ResNet\n",
    "    transfer_weights(base_resnet50, custom_resnet)\n",
    "\n",
    "    # Freeze layers in the main body\n",
    "    for layer in custom_resnet.layers:\n",
    "        if layer.name.startswith('conv'):\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.4) CALLBACKS & TRAIN (PHASE 1)\n",
    "    # ------------------------------------------------------\n",
    "    model_path_phase1 = f\"resnet50_cbam_classificationhead_fold{fold_index}_phase1.keras\"\n",
    "    callbacks_phase1 = [\n",
    "        EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase1, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase1 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE1,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase1\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 1\n",
    "    custom_resnet.load_weights(model_path_phase1)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.5) UNFREEZE & FINE-TUNING (PHASE 2)\n",
    "    # ------------------------------------------------------\n",
    "    for layer in custom_resnet.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    custom_resnet.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    model_path_phase2 = f\"resnet50_cbam_classificationhead_fold{fold_index}_phase2.keras\"\n",
    "    callbacks_phase2 = [\n",
    "        ReduceLROnPlateau(monitor='val_auc', factor=0.1, patience=3, mode='max', verbose=1),\n",
    "        EarlyStopping(monitor='val_auc', patience=7, restore_best_weights=True, mode='max', verbose=1),\n",
    "        ModelCheckpoint(model_path_phase2, monitor='val_auc', save_best_only=True, mode='max', verbose=1)\n",
    "    ]\n",
    "\n",
    "    history_phase2 = custom_resnet.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS_PHASE2,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=callbacks_phase2\n",
    "    )\n",
    "\n",
    "    # Load best weights from Phase 2\n",
    "    custom_resnet.load_weights(model_path_phase2)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4.6) EVALUATE ON THIS FOLD\n",
    "    # ------------------------------------------------------\n",
    "    loss, accuracy, auc_val = custom_resnet.evaluate(val_generator, verbose=0)\n",
    "    print(f\"FOLD {fold_index} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc_val:.4f}\")\n",
    "\n",
    "    fold_losses.append(loss)\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_aucs.append(auc_val)\n",
    "\n",
    "    # Check if this fold is the best so far\n",
    "    if auc_val > best_auc_across_folds:\n",
    "        best_auc_across_folds = auc_val\n",
    "        best_fold = fold_index\n",
    "\n",
    "    # Move to next fold\n",
    "    fold_index += 1\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5) CROSS-VALIDATION RESULTS\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"\\n=== CROSS-VALIDATION RESULTS ===\")\n",
    "print(f\"Average Loss over {k_folds} folds  : {np.mean(fold_losses):.4f} (± {np.std(fold_losses):.4f})\")\n",
    "print(f\"Average Accuracy over {k_folds} folds: {np.mean(fold_accuracies):.4f} (± {np.std(fold_accuracies):.4f})\")\n",
    "print(f\"Average AUC over {k_folds} folds     : {np.mean(fold_aucs):.4f} (± {np.std(fold_aucs):.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "account-management-Kww3qb6U",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
