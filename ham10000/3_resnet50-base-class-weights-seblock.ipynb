{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/home/rob/'\n",
    "csv_file = os.path.join(base, 'ham10000_data/HAM10000_metadata.csv')\n",
    "img_dir = os.path.join(base, 'ham10000_data/images')\n",
    "file_ext = '.jpg'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x + file_ext))\n",
    "class_names = df['dx'].unique()\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in sss.split(df, df['dx']):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "print(\"Train size: \", len(train_df))\n",
    "print(\"Train sizes per label and percentage:\")\n",
    "train_counts = train_df['dx'].value_counts()\n",
    "train_percentages = (train_counts / len(train_df)) * 100\n",
    "print(train_counts)\n",
    "print(train_percentages)\n",
    "\n",
    "print(\"\\nTest size: \", len(test_df))\n",
    "print(\"Test sizes per label and percentage:\")\n",
    "test_counts = test_df['dx'].value_counts()\n",
    "test_percentages = (test_counts / len(test_df)) * 100\n",
    "print(test_counts)\n",
    "print(test_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = datagen_test.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    ").repeat()\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: test_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, IMG_SIZE, IMG_SIZE, 3], [None, len(class_names)])\n",
    ").repeat()\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/best_model_resnet50.keras'\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=7, verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(df['dx']), y=df['dx'])\n",
    "class_weights_dict = {train_generator.class_indices[class_name]: weight\n",
    "                      for class_name, weight in zip(np.unique(df['dx']), class_weights_array)}\n",
    "\n",
    "print(class_weights_dict)\n",
    "print(train_generator.class_indices)\n",
    "dx_counts = train_df['dx'].value_counts()\n",
    "print(dx_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "validation_steps = len(test_df) // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Total Predictions: {len(test_generator) * BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Total Melanoma Predictions: {np.sum(test_df['dx'] == 'mel')}\")\n",
    "print(f\"Total Melanoma Correct Predictions: {np.sum(np.argmax(model.predict(test_generator), axis=1) == 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy'] + fine_tune_history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy'] + fine_tune_history.history['val_accuracy']\n",
    "loss = history.history['loss'] + fine_tune_history.history['loss']\n",
    "val_loss = history.history['val_loss'] + fine_tune_history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "plt.axvline(x=len(history.history['accuracy']), color='r', linestyle='--', label='Start of Fine-Tuning')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.axvline(x=len(history.history['loss']), color='r', linestyle='--', label='Start of Fine-Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_generator), axis=-1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.bincount(y_true)\n",
    "class_accuracies = np.diag(cm) / label_counts\n",
    "\n",
    "classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "total_counts = label_counts\n",
    "accuracies = class_accuracies\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.bar(classes, total_counts, alpha=0.7, label='Total Samples', color='blue')\n",
    "ax1.set_xlabel('Classes')\n",
    "ax1.set_ylabel('Total Samples', color='blue')\n",
    "ax1.set_title('Per-Class Total Samples and Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(classes, accuracies, color='orange', marker='o', label='Accuracy')\n",
    "ax2.set_ylabel('Accuracy', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall ROC AUC for multi-class classification\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = len(classes)\n",
    "y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "\n",
    "y_pred_prob = np.zeros_like(y_true_one_hot)\n",
    "for i, label in enumerate(y_pred):\n",
    "    y_pred_prob[i, label] = 1\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true_one_hot.ravel(), y_pred_prob.ravel())\n",
    "roc_auc = roc_auc_score(y_true_one_hot, y_pred_prob, average=\"micro\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", label=f\"Micro-Average ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Overall ROC Curve and AUC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
